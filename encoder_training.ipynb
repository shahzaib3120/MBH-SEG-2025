{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262cd5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !D:\\Learning\\UALBERTA\\nnUnet\\nnUNet\\set_env.bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334ff136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# compute canada\n",
    "os.environ[\"nnUNet_raw\"] = \"/home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_raw\"\n",
    "os.environ[\"nnUNet_preprocessed\"] = \"/home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = \"/home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_results\"\n",
    "\n",
    "csv_path = './case-wise_annotation.csv'\n",
    "\n",
    "\n",
    "# # local\n",
    "# os.environ[\"nnUNet_raw\"] = \"D:/Learning/UALBERTA/nnUNet/nnUNet_raw\"\n",
    "# os.environ[\"nnUNet_preprocessed\"] = \"D:/Learning/UALBERTA/nnUNet/nnUNet_preprocessed\"\n",
    "# os.environ[\"nnUNet_results\"] = \"D:/Learning/UALBERTA/nnUNet/nnUNet_results\"\n",
    "# csv_path = 'D:/Learning/UALBERTA/MBH_Train_2025_case-label/case-wise_annotation.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import time\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import blosc2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from acvl_utils.cropping_and_padding.bounding_boxes import crop_and_pad_nd\n",
    "from batchgenerators.dataloading.nondet_multi_threaded_augmenter import (\n",
    "    NonDetMultiThreadedAugmenter,\n",
    ")\n",
    "from batchgenerators.dataloading.single_threaded_augmenter import (\n",
    "    SingleThreadedAugmenter,\n",
    ")\n",
    "from batchgenerators.utilities.file_and_folder_operations import (\n",
    "    isfile,\n",
    "    join,\n",
    "    load_json,\n",
    "    load_pickle,\n",
    "    save_json,\n",
    ")\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "from nnunetv2.training.dataloading.data_loader import nnUNetDataLoader\n",
    "from nnunetv2.training.dataloading.nnunet_dataset import (\n",
    "    nnUNetBaseDataset,\n",
    "    nnUNetDatasetBlosc2,\n",
    ")\n",
    "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
    "from nnunetv2.utilities.crossval_split import generate_crossval_split\n",
    "from nnunetv2.utilities.default_n_proc_DA import get_allowed_n_proc_DA\n",
    "from nnunetv2.utilities.helpers import dummy_context\n",
    "from nnunetv2.utilities.label_handling.label_handling import LabelManager\n",
    "from scipy.ndimage import label\n",
    "from threadpoolctl import threadpool_limits\n",
    "from torch import autocast\n",
    "from torch import distributed as dist\n",
    "from totalsegmentator.python_api import totalsegmentator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c55ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device  = torch.device(type=\"cuda\") if torch.cuda.is_available() else torch.device(type=\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497b885",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c7d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnUNetDatasetBlosc2MultiLabel(nnUNetDatasetBlosc2):\n",
    "    def __init__(self, folder: str, csv_path: str, identifiers: List[str] = None,\n",
    "                 folder_with_segs_from_previous_stage: str = None):\n",
    "        super().__init__(folder, identifiers, folder_with_segs_from_previous_stage)\n",
    "        self.csv_path = csv_path\n",
    "        # csv header\n",
    "        # patientID_studyID,any,epidural,intraparenchymal,intraventricular,subarachnoid,subdural\n",
    "        # ID_00526c11_ID_d6296de728,1,0,1,0,0,0\n",
    "            \n",
    "        # ID_00526c11_ID_d6296de728 is the identifier\n",
    "        # remove the column \"any\"\n",
    "\n",
    "        self.csv_df = pd.read_csv(csv_path)\n",
    "        self.csv_df = self.csv_df.drop(columns=['any'])\n",
    "        self.csv_df['patientID_studyID'] = self.csv_df['patientID_studyID'].str.split('_').str[0]\n",
    "        self.csv_df['patientID'] = self.csv_df['patientID_studyID'].str.split('_').str[0]\n",
    "        self.csv_df['studyID'] = self.csv_df['patientID_studyID'].str.split('_').str[1]\n",
    "        self.csv_df['patientID'] = self.csv_df['patientID'].str.split('_').str[0]\n",
    "\n",
    "    def __getitem__(self, identifier):\n",
    "        return self.load_case(identifier)\n",
    "\n",
    "    def load_case(self, identifier):\n",
    "        dparams = {\n",
    "            'nthreads': 1\n",
    "        }\n",
    "        data_b2nd_file = join(self.source_folder, identifier + '.b2nd')\n",
    "\n",
    "        # mmap does not work with Windows -> https://github.com/MIC-DKFZ/nnUNet/issues/2723\n",
    "        mmap_kwargs = {} if os.name == \"nt\" else {'mmap_mode': 'r'}\n",
    "        data = blosc2.open(urlpath=data_b2nd_file, mode='r', dparams=dparams, **mmap_kwargs)\n",
    "\n",
    "        # label for multi-label classification\n",
    "        # the csv may or may not include the entry for the identifier\n",
    "        # if it does, then we need to get the label from the csv\n",
    "        # if it does not, then we need to return a label of all zeros\n",
    "        row = self.csv_df[self.csv_df['patientID_studyID'] == identifier]\n",
    "        if len(row) > 0:\n",
    "            label = np.array([row['epidural'], row['intraparenchymal'], row['intraventricular'], row['subarachnoid'], row['subdural']])\n",
    "        else:\n",
    "            label = np.zeros(5)\n",
    "        properties = load_pickle(join(self.source_folder, identifier + '.pkl'))\n",
    "        return data, label, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a87bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnUNetDataLoaderMultiLabel(nnUNetDataLoader):\n",
    "    # \n",
    "    # data: nnUNetBaseDataset,\n",
    "    # batch_size: int,\n",
    "    # patch_size: Union[List[int], Tuple[int, ...], np.ndarray],\n",
    "    # final_patch_size: Union[List[int], Tuple[int, ...], np.ndarray],\n",
    "    # label_manager: LabelManager,\n",
    "    # oversample_foreground_percent: float = 0.0,\n",
    "    # sampling_probabilities: Union[List[int], Tuple[int, ...], np.ndarray] = None,\n",
    "    # pad_sides: Union[List[int], Tuple[int, ...]] = None,\n",
    "    # probabilistic_oversampling: bool = False,\n",
    "    # transforms=None\n",
    "    def __init__(self,\n",
    "                data: nnUNetDatasetBlosc2MultiLabel,\n",
    "                batch_size: int,\n",
    "                patch_size: Union[List[int], Tuple[int, ...], np.ndarray],\n",
    "                final_patch_size: Union[List[int], Tuple[int, ...], np.ndarray],\n",
    "                label_manager: LabelManager,\n",
    "                oversample_foreground_percent: float = 0.0,\n",
    "                sampling_probabilities: Union[List[int], Tuple[int, ...], np.ndarray] = None,\n",
    "                pad_sides: Union[List[int], Tuple[int, ...]] = None,\n",
    "                probabilistic_oversampling: bool = False,\n",
    "                transforms=None):\n",
    "        \"\"\"\n",
    "        DataLoader for multi-label classification.\n",
    "        \"\"\"\n",
    "        # call parent with dummy label_manager (not needed for multilabel)\n",
    "        super().__init__(data=data,\n",
    "                         batch_size=batch_size,\n",
    "                         patch_size=patch_size,\n",
    "                         final_patch_size=final_patch_size,\n",
    "                         label_manager=label_manager,\n",
    "                         oversample_foreground_percent=oversample_foreground_percent,\n",
    "                         sampling_probabilities=sampling_probabilities,\n",
    "                         pad_sides=pad_sides,\n",
    "                         probabilistic_oversampling=probabilistic_oversampling,\n",
    "                         transforms=transforms)\n",
    "\n",
    "        # Override attributes not used in multilabel case\n",
    "        self.data_shape = None  # will infer dynamically\n",
    "        self.seg_shape = None\n",
    "        self.has_ignore = False\n",
    "        self.annotated_classes_key = None\n",
    "\n",
    "    def determine_shapes(self):\n",
    "        # For multilabel, determine data shape based on patch size\n",
    "        data, label, props = self._data.load_case(self._data.identifiers[0])\n",
    "        num_channels = data.shape[0]\n",
    "        data_shape = (self.batch_size, num_channels, *self.patch_size)\n",
    "        # labels are vectors of length 5\n",
    "        label_shape = (self.batch_size, 5)\n",
    "        return data_shape, label_shape\n",
    "\n",
    "    def generate_train_batch(self):\n",
    "        selected_keys = self.get_indices()\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for i in selected_keys:\n",
    "            data, label, properties = self._data.load_case(i)\n",
    "\n",
    "            # crop or pad if needed\n",
    "            shape = data.shape[1:]\n",
    "            bbox_lbs = [0 for _ in shape]\n",
    "            bbox_ubs = [min(shape[d], self.patch_size[d]) for d in range(len(shape))]\n",
    "            bbox = [[l, u] for l, u in zip(bbox_lbs, bbox_ubs)]\n",
    "            data_cropped = crop_and_pad_nd(data, bbox, 0)\n",
    "\n",
    "            images.append(torch.from_numpy(data_cropped).float())\n",
    "            labels.append(torch.from_numpy(label).float())\n",
    "\n",
    "        images = torch.stack(images)\n",
    "        labels = torch.stack(labels)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            with torch.no_grad():\n",
    "                with threadpool_limits(limits=1, user_api=None):\n",
    "                    transformed_imgs = []\n",
    "                    for b in range(images.shape[0]):\n",
    "                        tmp = self.transforms(image=images[b])\n",
    "                        transformed_imgs.append(tmp['image'])\n",
    "                    images = torch.stack(transformed_imgs)\n",
    "\n",
    "        return {'data': images, 'target': labels, 'keys': selected_keys}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9010a3",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e239c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    \"\"\"Classification head for multi-label classification.\n",
    "    \n",
    "    This module takes encoder features and outputs predictions for multiple binary\n",
    "    classification tasks. It applies global average pooling followed by a fully\n",
    "    connected layer with sigmoid activation.\n",
    "    \n",
    "    Args:\n",
    "        in_features (int): Number of input features from the encoder.\n",
    "        num_classes (int): Number of output classes for multi-label classification.\n",
    "        dropout_rate (float, optional): Dropout rate for regularization. Defaults to 0.5.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Predictions with shape (batch_size, num_classes) with sigmoid activation.\n",
    "        \n",
    "    Example:\n",
    "        >>> head = ClassificationHead(in_features=512, num_classes=5)\n",
    "        >>> encoder_features = torch.randn(8, 512, 32, 32, 16)  # (B, C, H, W, D)\n",
    "        >>> predictions = head(encoder_features)  # (8, 5)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features: int, num_classes: int, dropout_rate: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x shape: (batch_size, channels, height, width, depth)\n",
    "        x = self.global_pool(x)  # (batch_size, channels, 1, 1, 1)\n",
    "        x = torch.flatten(x, 1)  # (batch_size, channels)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)   # (batch_size, num_classes)\n",
    "        return torch.sigmoid(x)  # Apply sigmoid for multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNetTrainerMultiLabel class created successfully!\n"
     ]
    }
   ],
   "source": [
    "class nnUNetTrainerMultiLabel(nnUNetTrainer):\n",
    "    \"\"\"Multi-label classification trainer based on nnUNet.\n",
    "    \n",
    "    This trainer extends the standard nnUNet trainer for multi-label classification tasks.\n",
    "    It modifies the network architecture to use only the encoder with a classification head,\n",
    "    changes the loss function to binary cross-entropy, and adapts the training/validation\n",
    "    steps to handle multi-label targets.\n",
    "    \n",
    "    Key differences from the base trainer:\n",
    "    1. Uses encoder-only architecture with classification head\n",
    "    2. Uses binary cross-entropy loss for multi-label classification  \n",
    "    3. Uses nnUNetDatasetBlosc2MultiLabel dataset class\n",
    "    4. Modifies train/validation steps for classification metrics\n",
    "    \n",
    "    Args:\n",
    "        plans (dict): nnUNet plans dictionary containing configuration.\n",
    "        configuration (str): Configuration name (e.g., '3d_fullres').\n",
    "        fold (int): Cross-validation fold number.\n",
    "        dataset_json (dict): Dataset JSON containing metadata.\n",
    "        csv_path (str): Path to CSV file containing multi-label annotations.\n",
    "        device (torch.device, optional): Training device. Defaults to CUDA.\n",
    "        \n",
    "    Example:\n",
    "        >>> trainer = nnUNetTrainerMultiLabel(\n",
    "        ...     plans=plans,\n",
    "        ...     configuration='3d_fullres', \n",
    "        ...     fold=0,\n",
    "        ...     dataset_json=dataset_json,\n",
    "        ...     csv_path='/path/to/labels.csv'\n",
    "        ... )\n",
    "        >>> trainer.initialize()\n",
    "        >>> trainer.run_training()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, \n",
    "                 device: torch.device = torch.device('cuda')):\n",
    "        # Initialize parent class\n",
    "        self.csv_path = csv_path\n",
    "        super().__init__(plans, configuration, fold, dataset_json, device)\n",
    "        self.num_classes = 5  # epidural, intraparenchymal, intraventricular, subarachnoid, subdural\n",
    "        self.enable_deep_supervision = False\n",
    "        # self.logger.my_fantastic_logging = {\n",
    "        #     'mean_fg_dice': list(),\n",
    "        #     'ema_fg_dice': list(),\n",
    "        #     'dice_per_class_or_region': list(),\n",
    "        #     'train_losses': list(),\n",
    "        #     'val_losses': list(),\n",
    "        #     'lrs': list(),\n",
    "        #     'epoch_start_timestamps': list(),\n",
    "        #     'epoch_end_timestamps': list()\n",
    "        # }\n",
    "        \n",
    "        \n",
    "        # extent the logger\n",
    "        class_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "        \n",
    "        self.logger.my_fantastic_logging = {\n",
    "            **self.logger.my_fantastic_logging,\n",
    "            **{f'val_acc_{class_name}': list() for class_name in class_names},\n",
    "            **{f'val_acc_mean': list()}\n",
    "        }\n",
    "        \n",
    "        print(self.logger.my_fantastic_logging.keys())\n",
    "        \n",
    "    def initialize(self):\n",
    "        if not self.was_initialized:\n",
    "            # Set batch size and oversampling\n",
    "            self._set_batch_size_and_oversample()\n",
    "\n",
    "            # Determine input channels\n",
    "            from nnunetv2.utilities.label_handling.label_handling import (\n",
    "                determine_num_input_channels,\n",
    "            )\n",
    "            self.num_input_channels = determine_num_input_channels(\n",
    "                self.plans_manager, self.configuration_manager, self.dataset_json\n",
    "            )\n",
    "\n",
    "            # Build the segmentation network first to get encoder\n",
    "            self.segmentation_network = self.build_network_architecture(\n",
    "                self.configuration_manager.network_arch_class_name,\n",
    "                self.configuration_manager.network_arch_init_kwargs,\n",
    "                self.configuration_manager.network_arch_init_kwargs_req_import,\n",
    "                self.num_input_channels,\n",
    "                self.label_manager.num_segmentation_heads,\n",
    "                self.enable_deep_supervision\n",
    "            )\n",
    "            \n",
    "            # Extract encoder and add classification head\n",
    "            self.network = self._build_classification_network(self.segmentation_network)\n",
    "            self.network = self.network.to(self.device)\n",
    "            \n",
    "            # Compile network if enabled\n",
    "            if self._do_i_compile():\n",
    "                self.print_to_log_file('Using torch.compile...')\n",
    "                self.network = torch.compile(self.network)\n",
    "\n",
    "            # Configure optimizers\n",
    "            self.optimizer, self.lr_scheduler = self.configure_optimizers()\n",
    "            \n",
    "            # Wrap in DDP if needed\n",
    "            if self.is_ddp:\n",
    "                self.network = torch.nn.SyncBatchNorm.convert_sync_batchnorm(self.network)\n",
    "                from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "                self.network = DDP(self.network, device_ids=[self.local_rank])\n",
    "\n",
    "            # Build loss function\n",
    "            self.loss = self._build_loss()\n",
    "\n",
    "            # Set custom dataset class\n",
    "            self.dataset_class = nnUNetDatasetBlosc2MultiLabel\n",
    "\n",
    "            self.was_initialized = True\n",
    "        else:\n",
    "            raise RuntimeError(\"Trainer already initialized\")\n",
    "    \n",
    "    def _build_classification_network(self, segmentation_network):\n",
    "        \"\"\"Build classification network using encoder from segmentation network.\n",
    "        \n",
    "        Args:\n",
    "            segmentation_network: Full nnUNet segmentation network.\n",
    "            \n",
    "        Returns:\n",
    "            nn.Module: Classification network with encoder + classification head.\n",
    "        \"\"\"\n",
    "        # Create a wrapper that combines encoder and classification head\n",
    "        class EncoderClassificationNetwork(nn.Module):\n",
    "            def __init__(self, encoder, classification_head):\n",
    "                super().__init__()\n",
    "                self.encoder = encoder\n",
    "                self.classification_head = classification_head\n",
    "                # dummy decoder module\n",
    "                self.decoder = nn.Module()\n",
    "                \n",
    "            def forward(self, x):\n",
    "                # Get encoder features (before final segmentation layers)\n",
    "                encoder_features = self.encoder(x)\n",
    "                \n",
    "                # If encoder returns multiple scales (deep supervision), use the highest resolution\n",
    "                if isinstance(encoder_features, (list, tuple)):\n",
    "                    encoder_features = encoder_features[0]\n",
    "                    \n",
    "                # Apply classification head\n",
    "                return self.classification_head(encoder_features)\n",
    "        \n",
    "        # Extract encoder part - this depends on the specific architecture\n",
    "        # For most nnUNet architectures, we can use the encoder directly\n",
    "        if hasattr(segmentation_network, 'encoder'):\n",
    "            encoder = segmentation_network.encoder\n",
    "            # Get the number of features from the encoder output\n",
    "            # This is architecture-dependent, we'll estimate from the decoder input\n",
    "            if hasattr(segmentation_network, 'decoder') and hasattr(segmentation_network.decoder, 'conv_blocks_context'):\n",
    "                # For Generic_UNet architecture\n",
    "                encoder_features = segmentation_network.decoder.conv_blocks_context[-1].output_channels\n",
    "            else:\n",
    "                # Fallback: assume 512 features (common for nnUNet)\n",
    "                encoder_features = 32\n",
    "        else:\n",
    "            # If no explicit encoder attribute, we'll use the whole network but modify the forward\n",
    "            # This is a more general approach that should work with most architectures\n",
    "            encoder = segmentation_network\n",
    "            encoder_features = 32  # This might need adjustment based on actual architecture\n",
    "            \n",
    "        # Create classification head\n",
    "        classification_head = ClassificationHead(\n",
    "            in_features=encoder_features,\n",
    "            num_classes=self.num_classes,\n",
    "            dropout_rate=0.5\n",
    "        )\n",
    "        \n",
    "        return EncoderClassificationNetwork(encoder, classification_head)\n",
    "    \n",
    "    def _build_loss(self):\n",
    "        \"\"\"Build binary cross-entropy loss for multi-label classification.\n",
    "        \n",
    "        Returns:\n",
    "            nn.Module: Binary cross-entropy loss with logits.\n",
    "        \"\"\"\n",
    "        return nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def get_tr_and_val_datasets(self):\n",
    "        \"\"\"Get training and validation datasets using custom multi-label dataset class.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (training_dataset, validation_dataset)\n",
    "        \"\"\"\n",
    "        # Create dataset split\n",
    "        tr_keys, val_keys = self.do_split()\n",
    "\n",
    "        # Load datasets with CSV path for multi-label annotations\n",
    "        dataset_tr = self.dataset_class(\n",
    "            folder=self.preprocessed_dataset_folder,\n",
    "            csv_path=self.csv_path,\n",
    "            identifiers=tr_keys,\n",
    "            folder_with_segs_from_previous_stage=self.folder_with_segs_from_previous_stage\n",
    "        )\n",
    "        dataset_val = self.dataset_class(\n",
    "            folder=self.preprocessed_dataset_folder,\n",
    "            csv_path=self.csv_path,\n",
    "            identifiers=val_keys,\n",
    "            folder_with_segs_from_previous_stage=self.folder_with_segs_from_previous_stage\n",
    "        )\n",
    "        return dataset_tr, dataset_val\n",
    "    \n",
    "    def train_step(self, batch: dict) -> dict:\n",
    "        \"\"\"Execute one training step for multi-label classification.\n",
    "        \n",
    "        Args:\n",
    "            batch (dict): Batch containing 'data' and 'target' keys.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing loss value.\n",
    "        \"\"\"\n",
    "        data = batch['data']\n",
    "        target = batch['target']  # This will be the multi-label target from CSV\n",
    "\n",
    "        data = data.to(self.device, non_blocking=True)\n",
    "        target = target.to(self.device, non_blocking=True).float()  # Ensure float for BCE loss\n",
    "\n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with autocast(self.device.type, enabled=True) if self.device.type == 'cuda' else dummy_context():\n",
    "            output = self.network(data)  # Shape: (batch_size, num_classes)\n",
    "            loss = self.loss(output, target)\n",
    "\n",
    "        if self.grad_scaler is not None:\n",
    "            self.grad_scaler.scale(loss).backward()\n",
    "            self.grad_scaler.unscale_(self.optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "            self.grad_scaler.step(self.optimizer)\n",
    "            self.grad_scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return {'loss': loss.detach().cpu().numpy()}\n",
    "    \n",
    "    def validation_step(self, batch: dict) -> dict:\n",
    "        \"\"\"Execute one validation step for multi-label classification.\n",
    "        \n",
    "        Args:\n",
    "            batch (dict): Batch containing 'data' and 'target' keys.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing loss and predictions.\n",
    "        \"\"\"\n",
    "        data = batch['data']\n",
    "        target = batch['target']\n",
    "\n",
    "        data = data.to(self.device, non_blocking=True)\n",
    "        target = target.to(self.device, non_blocking=True).float()\n",
    "\n",
    "        with autocast(self.device.type, enabled=True) if self.device.type == 'cuda' else dummy_context():\n",
    "            output = self.network(data)\n",
    "            loss = self.loss(output, target)\n",
    "\n",
    "        # Convert predictions to binary (threshold at 0.5)\n",
    "        predictions = (torch.sigmoid(output) > 0.5).float()\n",
    "        \n",
    "        # Calculate per-class accuracy\n",
    "        correct_predictions = (predictions == target).float()\n",
    "        per_class_accuracy = correct_predictions.mean(dim=0)  # Average over batch\n",
    "        \n",
    "        return {\n",
    "            'loss': loss.detach().cpu().numpy(),\n",
    "            'predictions': predictions.detach().cpu().numpy(),\n",
    "            'targets': target.detach().cpu().numpy(),\n",
    "            'per_class_accuracy': per_class_accuracy.detach().cpu().numpy()\n",
    "        }\n",
    "    \n",
    "    def on_validation_epoch_end(self, val_outputs: List[dict]):\n",
    "        \"\"\"Process validation epoch results and log metrics.\n",
    "        \n",
    "        Args:\n",
    "            val_outputs (List[dict]): List of validation step outputs.\n",
    "        \"\"\"\n",
    "        from nnunetv2.utilities.collate_outputs import collate_outputs\n",
    "        \n",
    "        outputs = collate_outputs(val_outputs)\n",
    "\n",
    "        if self.is_ddp:\n",
    "            losses_val = [None for _ in range(dist.get_world_size())]\n",
    "            dist.all_gather_object(losses_val, outputs['loss'])\n",
    "            loss_here = np.vstack(losses_val).mean()\n",
    "            \n",
    "            accuracies_val = [None for _ in range(dist.get_world_size())]\n",
    "            dist.all_gather_object(accuracies_val, outputs['per_class_accuracy'])\n",
    "            per_class_acc = np.vstack(accuracies_val).mean(axis=0)\n",
    "        else:\n",
    "            loss_here = np.mean(outputs['loss'])\n",
    "            per_class_acc = np.mean(outputs['per_class_accuracy'], axis=0)\n",
    "\n",
    "        self.logger.log('val_losses', loss_here, self.current_epoch)\n",
    "\n",
    "        # Log per-class accuracies\n",
    "        class_names = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            self.logger.log(f'val_acc_{class_name}', per_class_acc[i], self.current_epoch)\n",
    "            \n",
    "        # Log mean accuracy across all classes\n",
    "        mean_accuracy = per_class_acc.mean()\n",
    "        self.logger.log('val_acc_mean', mean_accuracy, self.current_epoch)\n",
    "        \n",
    "        self.print_to_log_file(f\"Validation loss: {loss_here:.4f}\")\n",
    "        self.print_to_log_file(f\"Validation mean accuracy: {mean_accuracy:.4f}\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            self.print_to_log_file(f\"Validation {class_name} accuracy: {per_class_acc[i]:.4f}\")\n",
    "\n",
    "    def do_split(self):\n",
    "        \"\"\"\n",
    "        The default split is a 5 fold CV on all available training cases. nnU-Net will create a split (it is seeded,\n",
    "        so always the same) and save it as splits_final.json file in the preprocessed data directory.\n",
    "        Sometimes you may want to create your own split for various reasons. For this you will need to create your own\n",
    "        splits_final.json file. If this file is present, nnU-Net is going to use it and whatever splits are defined in\n",
    "        it. You can create as many splits in this file as you want. Note that if you define only 4 splits (fold 0-3)\n",
    "        and then set fold=4 when training (that would be the fifth split), nnU-Net will print a warning and proceed to\n",
    "        use a random 80:20 data split.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.dataset_class is None:\n",
    "            raise ValueError(\"Dataset class is not set\")\n",
    "\n",
    "        if self.fold == \"all\":\n",
    "            # if fold==all then we use all images for training and validation\n",
    "            case_identifiers = self.dataset_class.get_identifiers(\n",
    "                self.preprocessed_dataset_folder\n",
    "            )\n",
    "            tr_keys = case_identifiers\n",
    "            val_keys = tr_keys\n",
    "        else:\n",
    "            splits_file = join(\n",
    "                self.preprocessed_dataset_folder_base, \"splits_final.json\"\n",
    "            )\n",
    "            dataset = self.dataset_class(\n",
    "                self.preprocessed_dataset_folder,\n",
    "                identifiers=None,\n",
    "                folder_with_segs_from_previous_stage=self.folder_with_segs_from_previous_stage,\n",
    "                csv_path=self.csv_path\n",
    "            )\n",
    "            # if the split file does not exist we need to create it\n",
    "            if not isfile(splits_file):\n",
    "                self.print_to_log_file(\"Creating new 5-fold cross-validation split...\")\n",
    "                all_keys_sorted = list(np.sort(list(dataset.identifiers)))\n",
    "                splits = generate_crossval_split(\n",
    "                    all_keys_sorted, seed=12345, n_splits=5\n",
    "                )\n",
    "                save_json(splits, splits_file)\n",
    "\n",
    "            else:\n",
    "                self.print_to_log_file(\n",
    "                    \"Using splits from existing split file:\", splits_file\n",
    "                )\n",
    "                splits = load_json(splits_file)\n",
    "                self.print_to_log_file(f\"The split file contains {len(splits)} splits.\")\n",
    "\n",
    "            self.print_to_log_file(\"Desired fold for training: %d\" % self.fold)\n",
    "            if self.fold < len(splits):\n",
    "                tr_keys = splits[self.fold][\"train\"]\n",
    "                val_keys = splits[self.fold][\"val\"]\n",
    "                self.print_to_log_file(\n",
    "                    \"This split has %d training and %d validation cases.\"\n",
    "                    % (len(tr_keys), len(val_keys))\n",
    "                )\n",
    "            else:\n",
    "                self.print_to_log_file(\n",
    "                    \"INFO: You requested fold %d for training but splits \"\n",
    "                    \"contain only %d folds. I am now creating a \"\n",
    "                    \"random (but seeded) 80:20 split!\" % (self.fold, len(splits))\n",
    "                )\n",
    "                # if we request a fold that is not in the split file, create a random 80:20 split\n",
    "                rnd = np.random.RandomState(seed=12345 + self.fold)\n",
    "                keys = np.sort(list(dataset.identifiers))\n",
    "                idx_tr = rnd.choice(len(keys), int(len(keys) * 0.8), replace=False)\n",
    "                idx_val = [i for i in range(len(keys)) if i not in idx_tr]\n",
    "                tr_keys = [keys[i] for i in idx_tr]\n",
    "                val_keys = [keys[i] for i in idx_val]\n",
    "                self.print_to_log_file(\n",
    "                    \"This random 80:20 split has %d training and %d validation cases.\"\n",
    "                    % (len(tr_keys), len(val_keys))\n",
    "                )\n",
    "            if any([i in val_keys for i in tr_keys]):\n",
    "                self.print_to_log_file(\n",
    "                    \"WARNING: Some validation cases are also in the training set. Please check the \"\n",
    "                    \"splits.json or ignore if this is intentional.\"\n",
    "                )\n",
    "        return tr_keys, val_keys\n",
    "    \n",
    "    def get_dataloaders(self):\n",
    "        if self.dataset_class is None:\n",
    "            raise ValueError(\"Dataset class is not set\")\n",
    "\n",
    "        # we use the patch size to determine whether we need 2D or 3D dataloaders. We also use it to determine whether\n",
    "        # we need to use dummy 2D augmentation (in case of 3D training) and what our initial patch size should be\n",
    "        patch_size = self.configuration_manager.patch_size\n",
    "\n",
    "        # needed for deep supervision: how much do we need to downscale the segmentation targets for the different\n",
    "        # outputs?\n",
    "        deep_supervision_scales = self._get_deep_supervision_scales()\n",
    "\n",
    "        (\n",
    "            rotation_for_DA,\n",
    "            do_dummy_2d_data_aug,\n",
    "            initial_patch_size,\n",
    "            mirror_axes,\n",
    "        ) = self.configure_rotation_dummyDA_mirroring_and_inital_patch_size()\n",
    "\n",
    "        # training pipeline\n",
    "        tr_transforms = self.get_training_transforms(\n",
    "            patch_size,\n",
    "            rotation_for_DA,\n",
    "            deep_supervision_scales,\n",
    "            mirror_axes,\n",
    "            do_dummy_2d_data_aug,\n",
    "            use_mask_for_norm=self.configuration_manager.use_mask_for_norm,\n",
    "            is_cascaded=self.is_cascaded,\n",
    "            foreground_labels=self.label_manager.foreground_labels,\n",
    "            regions=self.label_manager.foreground_regions\n",
    "            if self.label_manager.has_regions\n",
    "            else None,\n",
    "            ignore_label=self.label_manager.ignore_label,\n",
    "        )\n",
    "\n",
    "        # validation pipeline\n",
    "        val_transforms = self.get_validation_transforms(\n",
    "            deep_supervision_scales,\n",
    "            is_cascaded=self.is_cascaded,\n",
    "            foreground_labels=self.label_manager.foreground_labels,\n",
    "            regions=self.label_manager.foreground_regions\n",
    "            if self.label_manager.has_regions\n",
    "            else None,\n",
    "            ignore_label=self.label_manager.ignore_label,\n",
    "        )\n",
    "\n",
    "        dataset_tr, dataset_val = self.get_tr_and_val_datasets()\n",
    "\n",
    "        dl_tr = nnUNetDataLoaderMultiLabel(\n",
    "            dataset_tr,\n",
    "            self.batch_size,\n",
    "            initial_patch_size,\n",
    "            self.configuration_manager.patch_size,\n",
    "            self.label_manager,\n",
    "            oversample_foreground_percent=self.oversample_foreground_percent,\n",
    "            sampling_probabilities=None,\n",
    "            pad_sides=None,\n",
    "            transforms=tr_transforms,\n",
    "            probabilistic_oversampling=self.probabilistic_oversampling,\n",
    "        )\n",
    "        dl_val = nnUNetDataLoaderMultiLabel(\n",
    "            dataset_val,\n",
    "            self.batch_size,\n",
    "            self.configuration_manager.patch_size,\n",
    "            self.configuration_manager.patch_size,\n",
    "            self.label_manager,\n",
    "            oversample_foreground_percent=self.oversample_foreground_percent,\n",
    "            sampling_probabilities=None,\n",
    "            pad_sides=None,\n",
    "            transforms=val_transforms,\n",
    "            probabilistic_oversampling=self.probabilistic_oversampling,\n",
    "        )\n",
    "\n",
    "        allowed_num_processes = get_allowed_n_proc_DA()\n",
    "        if allowed_num_processes == 0:\n",
    "            mt_gen_train = SingleThreadedAugmenter(dl_tr, None)\n",
    "            mt_gen_val = SingleThreadedAugmenter(dl_val, None)\n",
    "        else:\n",
    "            mt_gen_train = NonDetMultiThreadedAugmenter(\n",
    "                data_loader=dl_tr,\n",
    "                transform=None,\n",
    "                num_processes=allowed_num_processes,\n",
    "                num_cached=max(6, allowed_num_processes // 2),\n",
    "                seeds=None,\n",
    "                pin_memory=self.device.type == \"cuda\",\n",
    "                wait_time=0.002,\n",
    "            )\n",
    "            mt_gen_val = NonDetMultiThreadedAugmenter(\n",
    "                data_loader=dl_val,\n",
    "                transform=None,\n",
    "                num_processes=max(1, allowed_num_processes // 2),\n",
    "                num_cached=max(3, allowed_num_processes // 4),\n",
    "                seeds=None,\n",
    "                pin_memory=self.device.type == \"cuda\",\n",
    "                wait_time=0.002,\n",
    "            )\n",
    "        # # let's get this party started\n",
    "        _ = next(mt_gen_train)\n",
    "        _ = next(mt_gen_val)\n",
    "        return mt_gen_train, mt_gen_val\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.logger.log('epoch_end_timestamps', time.time(), self.current_epoch)\n",
    "\n",
    "        self.print_to_log_file('train_loss', np.round(self.logger.my_fantastic_logging['train_losses'][-1], decimals=4))\n",
    "        self.print_to_log_file('val_loss', np.round(self.logger.my_fantastic_logging['val_losses'][-1], decimals=4))\n",
    "        self.print_to_log_file(\n",
    "            f\"Epoch time: {np.round(self.logger.my_fantastic_logging['epoch_end_timestamps'][-1] - self.logger.my_fantastic_logging['epoch_start_timestamps'][-1], decimals=2)} s\")\n",
    "\n",
    "        # handling periodic checkpointing\n",
    "        current_epoch = self.current_epoch\n",
    "        if (current_epoch + 1) % self.save_every == 0 and current_epoch != (self.num_epochs - 1):\n",
    "            self.save_checkpoint(join(self.output_folder, 'checkpoint_latest.pth'))\n",
    "\n",
    "        # handle 'best' checkpointing. ema_fg_dice is computed by the logger and can be accessed like this\n",
    "        if self._best_ema is None or self.logger.my_fantastic_logging['val_acc_mean'][-1] > self._best_ema:\n",
    "            self._best_ema = self.logger.my_fantastic_logging['val_acc_mean'][-1]\n",
    "            self.print_to_log_file(f\"Yayy! New best EMA mean accuracy: {np.round(self._best_ema, decimals=4)}\")\n",
    "            self.save_checkpoint(join(self.output_folder, 'checkpoint_best.pth'))\n",
    "\n",
    "        if self.local_rank == 0:\n",
    "            self.logger.plot_progress_png(self.output_folder)\n",
    "\n",
    "        self.current_epoch += 1\n",
    "\n",
    "print(\"nnUNetTrainerMultiLabel class created successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5248a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.paths import nnUNet_preprocessed, nnUNet_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff9613b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed /home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "print(nnUNet_preprocessed, nnUNet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c7fd8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "dict_keys(['mean_fg_dice', 'ema_fg_dice', 'dice_per_class_or_region', 'train_losses', 'val_losses', 'lrs', 'epoch_start_timestamps', 'epoch_end_timestamps', 'val_acc_epidural', 'val_acc_intraparenchymal', 'val_acc_intraventricular', 'val_acc_subarachnoid', 'val_acc_subdural', 'val_acc_mean'])\n",
      "2025-08-25 05:35:19.337247: Using torch.compile...\n"
     ]
    }
   ],
   "source": [
    "# folder=\"../Dataset003_MBHClassify/Dataset003_MBHClassify/nnUNetPlans.json\",\n",
    "# csv_path=\"../case-wise_annotation.csv\",\n",
    "\n",
    "# plans = load_json('D:/Learning/UALBERTA/nnUnet/nnUNet_preprocessed/Dataset003_MBHClassify/nnUNetResEncUNetLPlans.json')\n",
    "# dataset_json = load_json('D:/Learning/UALBERTA/nnUnet/nnUNet_preprocessed/Dataset003_MBHClassify/dataset.json')\n",
    "\n",
    "plans = load_json('./nnUNet_preprocessed/Dataset003_MBHClassify/nnUNetResEncUNetLPlans.json')\n",
    "dataset_json = load_json('./nnUNet_preprocessed/Dataset003_MBHClassify/dataset.json')\n",
    "\n",
    "# Initialize the multi-label trainer\n",
    "trainer = nnUNetTrainerMultiLabel(\n",
    "    plans=plans,\n",
    "    configuration='3d_fullres',  # or whatever configuration you're using\n",
    "    fold=0,  # cross-validation fold\n",
    "    dataset_json=dataset_json,\n",
    "    # csv_path='D:/Learning/UALBERTA/MBH_Train_2025_case-label/case-wise_annotation.csv',\n",
    "    device=torch.device(type=\"cuda\")\n",
    ")\n",
    "\n",
    "# Initialize the trainer (this sets up the network, loss, optimizer, etc.)\n",
    "trainer.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f4b9742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 05:36:01.742972: do_dummy_2d_data_aug: True\n",
      "2025-08-25 05:36:01.794742: Using splits from existing split file: /home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed/Dataset003_MBHClassify/splits_final.json\n",
      "2025-08-25 05:36:01.802774: The split file contains 5 splits.\n",
      "2025-08-25 05:36:01.805505: Desired fold for training: 0\n",
      "2025-08-25 05:36:01.807780: This split has 1579 training and 395 validation cases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 320, 320], 'median_image_size_in_voxels': [59.5, 512.0, 512.0], 'spacing': [2.7851988792419435, 0.4882810115814209, 0.4882810115814209], 'normalization_schemes': ['CTNormalization', 'NoNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset003_MBHClassify', 'plans_name': 'nnUNetResEncUNetLPlans', 'original_median_spacing_after_transp': [5.0430450439453125, 0.4882810115814209, 0.4882810115814209], 'original_median_shape_after_transp': [32, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncL', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1241.0, 'mean': 47.706321716308594, 'median': 47.0, 'min': -3024.0, 'percentile_00_5': 11.0, 'percentile_99_5': 88.0, 'std': 18.544885635375977}, '1': {'max': 1.0, 'mean': 0.5401495099067688, 'median': 1.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 1.0, 'std': 0.49838340282440186}}} \n",
      "\n",
      "2025-08-25 05:36:18.849845: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-08-25 05:36:18.872418: \n",
      "2025-08-25 05:36:18.874318: Epoch 0\n",
      "2025-08-25 05:36:18.876951: Current learning rate: 0.01\n",
      "2025-08-25 05:37:19.288777: Validation loss: 0.6931\n",
      "2025-08-25 05:37:19.299007: Validation mean accuracy: 1.0000\n",
      "2025-08-25 05:37:19.302461: Validation epidural accuracy: 1.0000\n",
      "2025-08-25 05:37:19.304411: Validation intraparenchymal accuracy: 1.0000\n",
      "2025-08-25 05:37:19.307653: Validation intraventricular accuracy: 1.0000\n",
      "2025-08-25 05:37:19.309546: Validation subarachnoid accuracy: 1.0000\n",
      "2025-08-25 05:37:19.311459: Validation subdural accuracy: 1.0000\n",
      "2025-08-25 05:37:19.314704: train_loss 0.731\n",
      "2025-08-25 05:37:19.316788: val_loss 0.6931\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1381\u001b[39m, in \u001b[36mnnUNetTrainer.run_training\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1378\u001b[39m             val_outputs.append(\u001b[38;5;28mself\u001b[39m.validation_step(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataloader_val)))\n\u001b[32m   1379\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_validation_epoch_end(val_outputs)\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[38;5;28mself\u001b[39m.on_train_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1129\u001b[39m, in \u001b[36mnnUNetTrainer.on_epoch_end\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1126\u001b[39m \u001b[38;5;28mself\u001b[39m.print_to_log_file(\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m, np.round(\u001b[38;5;28mself\u001b[39m.logger.my_fantastic_logging[\u001b[33m'\u001b[39m\u001b[33mtrain_losses\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m], decimals=\u001b[32m4\u001b[39m))\n\u001b[32m   1127\u001b[39m \u001b[38;5;28mself\u001b[39m.print_to_log_file(\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, np.round(\u001b[38;5;28mself\u001b[39m.logger.my_fantastic_logging[\u001b[33m'\u001b[39m\u001b[33mval_losses\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m], decimals=\u001b[32m4\u001b[39m))\n\u001b[32m   1128\u001b[39m \u001b[38;5;28mself\u001b[39m.print_to_log_file(\u001b[33m'\u001b[39m\u001b[33mPseudo dice\u001b[39m\u001b[33m'\u001b[39m, [np.round(i, decimals=\u001b[32m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m                                        \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmy_fantastic_logging\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdice_per_class_or_region\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m])\n\u001b[32m   1130\u001b[39m \u001b[38;5;28mself\u001b[39m.print_to_log_file(\n\u001b[32m   1131\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.round(\u001b[38;5;28mself\u001b[39m.logger.my_fantastic_logging[\u001b[33m'\u001b[39m\u001b[33mepoch_end_timestamps\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.logger.my_fantastic_logging[\u001b[33m'\u001b[39m\u001b[33mepoch_start_timestamps\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m],\u001b[38;5;250m \u001b[39mdecimals=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1133\u001b[39m \u001b[38;5;66;03m# handling periodic checkpointing\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Run the training\n",
    "trainer.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68119a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranashah/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "predictor_3d = nnUNetPredictor(\n",
    "    tile_step_size=0.5,\n",
    "    use_gaussian=True,\n",
    "    use_mirroring=True,\n",
    "    perform_everything_on_device=True,\n",
    "    device=device,\n",
    "    verbose=False,\n",
    "    verbose_preprocessing=False,\n",
    "    allow_tqdm=True,\n",
    ")\n",
    "\n",
    "predictor_3d.initialize_from_trained_model_folder(\n",
    "    \"models/multiclass/nnUNetTrainerDA5__nnUNetResEncUNetLPlans__3d_fullres\",\n",
    "    use_folds=(0, 1, 2, 3, 4),\n",
    "    checkpoint_name=\"checkpoint_best.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8008f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = predictor_3d.network.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a6de9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualEncoder(\n",
      "  (stem): StackedConvBlocks(\n",
      "    (convs): Sequential(\n",
      "      (0): ConvDropoutNormReLU(\n",
      "        (conv): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "        (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (all_modules): Sequential(\n",
      "          (0): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "          (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(trainer.network.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf6dbb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualEncoder(\n",
      "  (stem): StackedConvBlocks(\n",
      "    (convs): Sequential(\n",
      "      (0): ConvDropoutNormReLU(\n",
      "        (conv): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "        (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (all_modules): Sequential(\n",
      "          (0): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "          (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(predictor_3d.network.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9fa42b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the encoder weights and gradients from predictor_3d.network.encoder into trainer.network.encoder\n",
    "\n",
    "trainer.network.encoder.load_state_dict(predictor_3d.network.encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bd2a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trainer network checkpoint\n",
    "\n",
    "torch.save(trainer.network.state_dict(), \"trainer_network_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca0937d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 05:06:07.953890: do_dummy_2d_data_aug: True\n",
      "2025-08-25 05:06:07.973145: Using splits from existing split file: /home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed/Dataset003_MBHClassify/splits_final.json\n",
      "2025-08-25 05:06:07.984360: The split file contains 5 splits.\n",
      "2025-08-25 05:06:07.987758: Desired fold for training: 0\n",
      "2025-08-25 05:06:07.992271: This split has 1579 training and 395 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "torch.Size([2, 2, 40, 320, 320])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "dataloader_train, dataloader_val = trainer.get_dataloaders()\n",
    "\n",
    "# get the first batch\n",
    "batch = next(iter(dataloader_train))\n",
    "\n",
    "# get the first image\n",
    "image = batch[\"data\"]\n",
    "\n",
    "# get the first label\n",
    "label = batch[\"target\"]\n",
    "\n",
    "# print the shape of the image and label\n",
    "print(image.shape)\n",
    "print(label.shape)\n",
    "\n",
    "# print the first image and label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65dccd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': array(0.9654873, dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24cfd9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 05:14:27.412729: do_dummy_2d_data_aug: True\n",
      "2025-08-25 05:14:27.439139: Using splits from existing split file: /home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed/Dataset003_MBHClassify/splits_final.json\n",
      "2025-08-25 05:14:27.450001: The split file contains 5 splits.\n",
      "2025-08-25 05:14:27.451560: Desired fold for training: 0\n",
      "2025-08-25 05:14:27.455410: This split has 1579 training and 395 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EncoderClassificationNetwork' object has no attribute 'decoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1363\u001b[39m, in \u001b[36mnnUNetTrainer.run_training\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_training\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_train_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.current_epoch, \u001b[38;5;28mself\u001b[39m.num_epochs):\n\u001b[32m   1366\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_epoch_start()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:905\u001b[39m, in \u001b[36mnnUNetTrainer.on_train_start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    902\u001b[39m maybe_mkdir_p(\u001b[38;5;28mself\u001b[39m.output_folder)\n\u001b[32m    904\u001b[39m \u001b[38;5;66;03m# make sure deep supervision is on in the network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_deep_supervision_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menable_deep_supervision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[38;5;28mself\u001b[39m.print_plans()\n\u001b[32m    908\u001b[39m empty_cache(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:892\u001b[39m, in \u001b[36mnnUNetTrainer.set_deep_supervision_enabled\u001b[39m\u001b[34m(self, enabled)\u001b[39m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, OptimizedModule):\n\u001b[32m    890\u001b[39m     mod = mod._orig_mod\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m.deep_supervision = enabled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'EncoderClassificationNetwork' object has no attribute 'decoder'"
     ]
    }
   ],
   "source": [
    "trainer.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4210182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 cases in the source folder\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpredictor_3d\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_from_files\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mfolder_with_segs_from_prev_stage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/inference/predict_from_raw_data.py:256\u001b[39m, in \u001b[36mnnUNetPredictor.predict_from_files\u001b[39m\u001b[34m(self, list_of_lists_or_source_folder, output_folder_or_list_of_truncated_output_files, save_probabilities, overwrite, num_processes_preprocessing, num_processes_segmentation_export, folder_with_segs_from_prev_stage, num_parts, part_id)\u001b[39m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m folder_with_segs_from_prev_stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \\\n\u001b[32m    250\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe requested configuration is a cascaded network. It requires the segmentations of the previous \u001b[39m\u001b[33m'\u001b[39m \\\n\u001b[32m    251\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstage (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.configuration_manager.previous_stage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) as input. Please provide the folder where\u001b[39m\u001b[33m'\u001b[39m \\\n\u001b[32m    252\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m they are located via folder_with_segs_from_prev_stage\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# sort out input and output filenames\u001b[39;00m\n\u001b[32m    255\u001b[39m list_of_lists_or_source_folder, output_filename_truncated, seg_from_prev_stage_files = \\\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_manage_input_and_output_lists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_of_lists_or_source_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m                                        \u001b[49m\u001b[43moutput_folder_or_list_of_truncated_output_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m                                        \u001b[49m\u001b[43mfolder_with_segs_from_prev_stage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                                        \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_of_lists_or_source_folder) == \u001b[32m0\u001b[39m:\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/inference/predict_from_raw_data.py:178\u001b[39m, in \u001b[36mnnUNetPredictor._manage_input_and_output_lists\u001b[39m\u001b[34m(self, list_of_lists_or_source_folder, output_folder_or_list_of_truncated_output_files, folder_with_segs_from_prev_stage, overwrite, part_id, num_parts, save_probabilities)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(list_of_lists_or_source_folder)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cases in the source folder\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    177\u001b[39m list_of_lists_or_source_folder = list_of_lists_or_source_folder[part_id::num_parts]\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m caseids = \u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_json\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfile_ending\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\n\u001b[32m    179\u001b[39m \u001b[43m           \u001b[49m\u001b[43mlist_of_lists_or_source_folder\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    181\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mI am processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_parts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (max process ID is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_parts\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, we start counting with 0!)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(caseids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cases that I would like to predict\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/inference/predict_from_raw_data.py:178\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(list_of_lists_or_source_folder)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cases in the source folder\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    177\u001b[39m list_of_lists_or_source_folder = list_of_lists_or_source_folder[part_id::num_parts]\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m caseids = [os.path.basename(\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)[:-(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset_json[\u001b[33m'\u001b[39m\u001b[33mfile_ending\u001b[39m\u001b[33m'\u001b[39m]) + \u001b[32m5\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m\n\u001b[32m    179\u001b[39m            list_of_lists_or_source_folder]\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    181\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mI am processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_parts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (max process ID is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_parts\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, we start counting with 0!)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(caseids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cases that I would like to predict\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "predictor_3d.predict_from_files(\"test_data\",\n",
    "                                \"output_data\",\n",
    "                                save_probabilities=True, overwrite=True,\n",
    "                                folder_with_segs_from_prev_stage=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f7c1e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 2, 1, 3, 3], expected input[2, 1, 40, 320, 320] to have 2 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpredictor_3d\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/dynamic_network_architectures/architectures/unet.py:180\u001b[39m, in \u001b[36mResidualEncoderUNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     skips = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.decoder(skips)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/dynamic_network_architectures/building_blocks/residual_encoders.py:137\u001b[39m, in \u001b[36mResidualEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     ret = []\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stages:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py:137\u001b[39m, in \u001b[36mStackedConvBlocks.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py:71\u001b[39m, in \u001b[36mConvDropoutNormReLU.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mall_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:725\u001b[39m, in \u001b[36mConv3d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:720\u001b[39m, in \u001b[36mConv3d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv3d(\n\u001b[32m    710\u001b[39m         F.pad(\n\u001b[32m    711\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    718\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    719\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [32, 2, 1, 3, 3], expected input[2, 1, 40, 320, 320] to have 2 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "predictor_3d.network(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c919b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranashah/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "predictor_3d = nnUNetPredictor(\n",
    "    tile_step_size=0.5,\n",
    "    use_gaussian=True,\n",
    "    use_mirroring=True,\n",
    "    perform_everything_on_device=True,\n",
    "    device=device,\n",
    "    verbose=False,\n",
    "    verbose_preprocessing=False,\n",
    "    allow_tqdm=True,\n",
    ")\n",
    "\n",
    "predictor_3d.initialize_from_trained_model_folder(\n",
    "    \"models/multiclass/nnUNetTrainerDA5__nnUNetResEncUNetLPlans__3d_fullres\",\n",
    "    use_folds=(0, 1, 2, 3, 4),\n",
    "    checkpoint_name=\"checkpoint_best.pth\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
