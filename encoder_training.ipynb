{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262cd5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !D:\\Learning\\UALBERTA\\nnUnet\\nnUNet\\set_env.bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334ff136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# compute canada\n",
    "os.environ['nnUNet_raw'] = '/home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_raw'\n",
    "os.environ['nnUNet_preprocessed'] = (\n",
    "\t'/home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed'\n",
    ")\n",
    "os.environ['nnUNet_results'] = '/home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_results'\n",
    "\n",
    "csv_path = './case-wise_annotation.csv'\n",
    "\n",
    "\n",
    "# # local\n",
    "# os.environ[\"nnUNet_raw\"] = \"D:/Learning/UALBERTA/nnUNet/nnUNet_raw\"\n",
    "# os.environ[\"nnUNet_preprocessed\"] = \"D:/Learning/UALBERTA/nnUNet/nnUNet_preprocessed\"\n",
    "# os.environ[\"nnUNet_results\"] = \"D:/Learning/UALBERTA/nnUNet/nnUNet_results\"\n",
    "# csv_path = 'D:/Learning/UALBERTA/MBH_Train_2025_case-label/case-wise_annotation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import time\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import blosc2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from acvl_utils.cropping_and_padding.bounding_boxes import crop_and_pad_nd\n",
    "from batchgenerators.dataloading.nondet_multi_threaded_augmenter import (\n",
    "\tNonDetMultiThreadedAugmenter,\n",
    ")\n",
    "from batchgenerators.dataloading.single_threaded_augmenter import (\n",
    "\tSingleThreadedAugmenter,\n",
    ")\n",
    "from batchgenerators.utilities.file_and_folder_operations import (\n",
    "\tisfile,\n",
    "\tjoin,\n",
    "\tload_json,\n",
    "\tload_pickle,\n",
    "\tsave_json,\n",
    ")\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "from nnunetv2.training.dataloading.data_loader import nnUNetDataLoader\n",
    "from nnunetv2.training.dataloading.nnunet_dataset import (\n",
    "\tnnUNetBaseDataset,\n",
    "\tnnUNetDatasetBlosc2,\n",
    ")\n",
    "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
    "from nnunetv2.utilities.crossval_split import generate_crossval_split\n",
    "from nnunetv2.utilities.default_n_proc_DA import get_allowed_n_proc_DA\n",
    "from nnunetv2.utilities.helpers import dummy_context\n",
    "from nnunetv2.utilities.label_handling.label_handling import LabelManager\n",
    "from scipy.ndimage import label\n",
    "from threadpoolctl import threadpool_limits\n",
    "from torch import autocast\n",
    "from torch import distributed as dist\n",
    "from totalsegmentator.python_api import totalsegmentator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c55ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(type='cuda') if torch.cuda.is_available() else torch.device(type='cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497b885",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c7d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnUNetDatasetBlosc2MultiLabel(nnUNetDatasetBlosc2):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tfolder: str,\n",
    "\t\tcsv_path: str,\n",
    "\t\tidentifiers: List[str] = None,\n",
    "\t\tfolder_with_segs_from_previous_stage: str = None,\n",
    "\t):\n",
    "\t\tsuper().__init__(folder, identifiers, folder_with_segs_from_previous_stage)\n",
    "\t\tself.csv_path = csv_path\n",
    "\t\t# csv header\n",
    "\t\t# patientID_studyID,any,epidural,intraparenchymal,intraventricular,subarachnoid,subdural\n",
    "\t\t# ID_00526c11_ID_d6296de728,1,0,1,0,0,0\n",
    "\n",
    "\t\t# ID_00526c11_ID_d6296de728 is the identifier\n",
    "\t\t# remove the column \"any\"\n",
    "\n",
    "\t\tself.csv_df = pd.read_csv(csv_path)\n",
    "\t\tself.csv_df = self.csv_df.drop(columns=['any'])\n",
    "\t\tself.csv_df['patientID_studyID'] = self.csv_df['patientID_studyID'].str.split('_').str[0]\n",
    "\t\tself.csv_df['patientID'] = self.csv_df['patientID_studyID'].str.split('_').str[0]\n",
    "\t\tself.csv_df['studyID'] = self.csv_df['patientID_studyID'].str.split('_').str[1]\n",
    "\t\tself.csv_df['patientID'] = self.csv_df['patientID'].str.split('_').str[0]\n",
    "\n",
    "\tdef __getitem__(self, identifier):\n",
    "\t\treturn self.load_case(identifier)\n",
    "\n",
    "\tdef load_case(self, identifier):\n",
    "\t\tdparams = {'nthreads': 1}\n",
    "\t\tdata_b2nd_file = join(self.source_folder, identifier + '.b2nd')\n",
    "\n",
    "\t\t# mmap does not work with Windows -> https://github.com/MIC-DKFZ/nnUNet/issues/2723\n",
    "\t\tmmap_kwargs = {} if os.name == 'nt' else {'mmap_mode': 'r'}\n",
    "\t\tdata = blosc2.open(urlpath=data_b2nd_file, mode='r', dparams=dparams, **mmap_kwargs)\n",
    "\n",
    "\t\t# label for multi-label classification\n",
    "\t\t# the csv may or may not include the entry for the identifier\n",
    "\t\t# if it does, then we need to get the label from the csv\n",
    "\t\t# if it does not, then we need to return a label of all zeros\n",
    "\t\trow = self.csv_df[self.csv_df['patientID_studyID'] == identifier]\n",
    "\t\tif len(row) > 0:\n",
    "\t\t\tlabel = np.array(\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\trow['epidural'],\n",
    "\t\t\t\t\trow['intraparenchymal'],\n",
    "\t\t\t\t\trow['intraventricular'],\n",
    "\t\t\t\t\trow['subarachnoid'],\n",
    "\t\t\t\t\trow['subdural'],\n",
    "\t\t\t\t]\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tlabel = np.zeros(5)\n",
    "\t\tproperties = load_pickle(join(self.source_folder, identifier + '.pkl'))\n",
    "\t\treturn data, label, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a87bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnUNetDataLoaderMultiLabel(nnUNetDataLoader):\n",
    "\t#\n",
    "\t# data: nnUNetBaseDataset,\n",
    "\t# batch_size: int,\n",
    "\t# patch_size: Union[List[int], Tuple[int, ...], np.ndarray],\n",
    "\t# final_patch_size: Union[List[int], Tuple[int, ...], np.ndarray],\n",
    "\t# label_manager: LabelManager,\n",
    "\t# oversample_foreground_percent: float = 0.0,\n",
    "\t# sampling_probabilities: Union[List[int], Tuple[int, ...], np.ndarray] = None,\n",
    "\t# pad_sides: Union[List[int], Tuple[int, ...]] = None,\n",
    "\t# probabilistic_oversampling: bool = False,\n",
    "\t# transforms=None\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tdata: nnUNetDatasetBlosc2MultiLabel,\n",
    "\t\tbatch_size: int,\n",
    "\t\tpatch_size: Union[List[int], Tuple[int, ...], np.ndarray],\n",
    "\t\tfinal_patch_size: Union[List[int], Tuple[int, ...], np.ndarray],\n",
    "\t\tlabel_manager: LabelManager,\n",
    "\t\toversample_foreground_percent: float = 0.0,\n",
    "\t\tsampling_probabilities: Union[List[int], Tuple[int, ...], np.ndarray] = None,\n",
    "\t\tpad_sides: Union[List[int], Tuple[int, ...]] = None,\n",
    "\t\tprobabilistic_oversampling: bool = False,\n",
    "\t\ttransforms=None,\n",
    "\t):\n",
    "\t\t\"\"\"\n",
    "\t\tDataLoader for multi-label classification.\n",
    "\t\t\"\"\"\n",
    "\t\t# call parent with dummy label_manager (not needed for multilabel)\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tdata=data,\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tpatch_size=patch_size,\n",
    "\t\t\tfinal_patch_size=final_patch_size,\n",
    "\t\t\tlabel_manager=label_manager,\n",
    "\t\t\toversample_foreground_percent=oversample_foreground_percent,\n",
    "\t\t\tsampling_probabilities=sampling_probabilities,\n",
    "\t\t\tpad_sides=pad_sides,\n",
    "\t\t\tprobabilistic_oversampling=probabilistic_oversampling,\n",
    "\t\t\ttransforms=transforms,\n",
    "\t\t)\n",
    "\n",
    "\t\t# Override attributes not used in multilabel case\n",
    "\t\tself.data_shape = None  # will infer dynamically\n",
    "\t\tself.seg_shape = None\n",
    "\t\tself.has_ignore = False\n",
    "\t\tself.annotated_classes_key = None\n",
    "\n",
    "\tdef determine_shapes(self):\n",
    "\t\t# For multilabel, determine data shape based on patch size\n",
    "\t\tdata, label, props = self._data.load_case(self._data.identifiers[0])\n",
    "\t\tnum_channels = data.shape[0]\n",
    "\t\tdata_shape = (self.batch_size, num_channels, *self.patch_size)\n",
    "\t\t# labels are vectors of length 5\n",
    "\t\tlabel_shape = (self.batch_size, 5)\n",
    "\t\treturn data_shape, label_shape\n",
    "\n",
    "\tdef generate_train_batch(self):\n",
    "\t\tselected_keys = self.get_indices()\n",
    "\t\timages = []\n",
    "\t\tlabels = []\n",
    "\n",
    "\t\tfor i in selected_keys:\n",
    "\t\t\tdata, label, properties = self._data.load_case(i)\n",
    "\n",
    "\t\t\t# crop or pad if needed\n",
    "\t\t\tshape = data.shape[1:]\n",
    "\t\t\tbbox_lbs = [0 for _ in shape]\n",
    "\t\t\tbbox_ubs = [min(shape[d], self.patch_size[d]) for d in range(len(shape))]\n",
    "\t\t\tbbox = [[l, u] for l, u in zip(bbox_lbs, bbox_ubs)]\n",
    "\t\t\tdata_cropped = crop_and_pad_nd(data, bbox, 0)\n",
    "\n",
    "\t\t\timages.append(torch.from_numpy(data_cropped).float())\n",
    "\t\t\tlabels.append(torch.from_numpy(label).float())\n",
    "\n",
    "\t\timages = torch.stack(images)\n",
    "\t\tlabels = torch.stack(labels)\n",
    "\n",
    "\t\tif self.transforms is not None:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\twith threadpool_limits(limits=1, user_api=None):\n",
    "\t\t\t\t\ttransformed_imgs = []\n",
    "\t\t\t\t\tfor b in range(images.shape[0]):\n",
    "\t\t\t\t\t\ttmp = self.transforms(image=images[b])\n",
    "\t\t\t\t\t\ttransformed_imgs.append(tmp['image'])\n",
    "\t\t\t\t\timages = torch.stack(transformed_imgs)\n",
    "\n",
    "\t\treturn {'data': images, 'target': labels, 'keys': selected_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9010a3",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e239c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "\t\"\"\"Classification head for multi-label classification.\n",
    "\n",
    "\tThis module takes encoder features and outputs predictions for multiple binary\n",
    "\tclassification tasks. It applies global average pooling followed by a fully\n",
    "\tconnected layer with sigmoid activation.\n",
    "\n",
    "\tArgs:\n",
    "\t    in_features (int): Number of input features from the encoder.\n",
    "\t    num_classes (int): Number of output classes for multi-label classification.\n",
    "\t    dropout_rate (float, optional): Dropout rate for regularization. Defaults to 0.5.\n",
    "\n",
    "\tReturns:\n",
    "\t    torch.Tensor: Predictions with shape (batch_size, num_classes) with sigmoid activation.\n",
    "\n",
    "\tExample:\n",
    "\t    >>> head = ClassificationHead(in_features=512, num_classes=5)\n",
    "\t    >>> encoder_features = torch.randn(8, 512, 32, 32, 16)  # (B, C, H, W, D)\n",
    "\t    >>> predictions = head(encoder_features)  # (8, 5)\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, in_features: int, num_classes: int, dropout_rate: float = 0.5):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.global_pool = nn.AdaptiveAvgPool3d(1)\n",
    "\t\tself.dropout = nn.Dropout(dropout_rate)\n",
    "\t\tself.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\t# x shape: (batch_size, channels, height, width, depth)\n",
    "\t\tx = self.global_pool(x)  # (batch_size, channels, 1, 1, 1)\n",
    "\t\tx = torch.flatten(x, 1)  # (batch_size, channels)\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = self.classifier(x)  # (batch_size, num_classes)\n",
    "\t\treturn torch.sigmoid(x)  # Apply sigmoid for multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNetTrainerMultiLabel class created successfully!\n"
     ]
    }
   ],
   "source": [
    "class nnUNetTrainerMultiLabel(nnUNetTrainer):\n",
    "\t\"\"\"Multi-label classification trainer based on nnUNet.\n",
    "\n",
    "\tThis trainer extends the standard nnUNet trainer for multi-label classification tasks.\n",
    "\tIt modifies the network architecture to use only the encoder with a classification head,\n",
    "\tchanges the loss function to binary cross-entropy, and adapts the training/validation\n",
    "\tsteps to handle multi-label targets.\n",
    "\n",
    "\tKey differences from the base trainer:\n",
    "\t1. Uses encoder-only architecture with classification head\n",
    "\t2. Uses binary cross-entropy loss for multi-label classification\n",
    "\t3. Uses nnUNetDatasetBlosc2MultiLabel dataset class\n",
    "\t4. Modifies train/validation steps for classification metrics\n",
    "\n",
    "\tArgs:\n",
    "\t    plans (dict): nnUNet plans dictionary containing configuration.\n",
    "\t    configuration (str): Configuration name (e.g., '3d_fullres').\n",
    "\t    fold (int): Cross-validation fold number.\n",
    "\t    dataset_json (dict): Dataset JSON containing metadata.\n",
    "\t    csv_path (str): Path to CSV file containing multi-label annotations.\n",
    "\t    device (torch.device, optional): Training device. Defaults to CUDA.\n",
    "\n",
    "\tExample:\n",
    "\t    >>> trainer = nnUNetTrainerMultiLabel(\n",
    "\t    ...     plans=plans,\n",
    "\t    ...     configuration='3d_fullres',\n",
    "\t    ...     fold=0,\n",
    "\t    ...     dataset_json=dataset_json,\n",
    "\t    ...     csv_path='/path/to/labels.csv',\n",
    "\t    ... )\n",
    "\t    >>> trainer.initialize()\n",
    "\t    >>> trainer.run_training()\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tplans: dict,\n",
    "\t\tconfiguration: str,\n",
    "\t\tfold: int,\n",
    "\t\tdataset_json: dict,\n",
    "\t\tdevice: torch.device = torch.device('cuda'),\n",
    "\t):\n",
    "\t\t# Initialize parent class\n",
    "\t\tself.csv_path = csv_path\n",
    "\t\tsuper().__init__(plans, configuration, fold, dataset_json, device)\n",
    "\t\tself.num_classes = 5  # epidural, intraparenchymal, intraventricular, subarachnoid, subdural\n",
    "\t\tself.enable_deep_supervision = False\n",
    "\t\t# self.logger.my_fantastic_logging = {\n",
    "\t\t#     'mean_fg_dice': list(),\n",
    "\t\t#     'ema_fg_dice': list(),\n",
    "\t\t#     'dice_per_class_or_region': list(),\n",
    "\t\t#     'train_losses': list(),\n",
    "\t\t#     'val_losses': list(),\n",
    "\t\t#     'lrs': list(),\n",
    "\t\t#     'epoch_start_timestamps': list(),\n",
    "\t\t#     'epoch_end_timestamps': list()\n",
    "\t\t# }\n",
    "\n",
    "\t\t# extent the logger\n",
    "\t\tclass_names = [\n",
    "\t\t\t'epidural',\n",
    "\t\t\t'intraparenchymal',\n",
    "\t\t\t'intraventricular',\n",
    "\t\t\t'subarachnoid',\n",
    "\t\t\t'subdural',\n",
    "\t\t]\n",
    "\n",
    "\t\tself.logger.my_fantastic_logging = {\n",
    "\t\t\t**self.logger.my_fantastic_logging,\n",
    "\t\t\t**{f'val_acc_{class_name}': list() for class_name in class_names},\n",
    "\t\t\t**{f'val_acc_mean': list()},\n",
    "\t\t}\n",
    "\n",
    "\t\tprint(self.logger.my_fantastic_logging.keys())\n",
    "\n",
    "\tdef initialize(self):\n",
    "\t\tif not self.was_initialized:\n",
    "\t\t\t# Set batch size and oversampling\n",
    "\t\t\tself._set_batch_size_and_oversample()\n",
    "\n",
    "\t\t\t# Determine input channels\n",
    "\t\t\tfrom nnunetv2.utilities.label_handling.label_handling import (\n",
    "\t\t\t\tdetermine_num_input_channels,\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tself.num_input_channels = determine_num_input_channels(\n",
    "\t\t\t\tself.plans_manager, self.configuration_manager, self.dataset_json\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# Build the segmentation network first to get encoder\n",
    "\t\t\tself.segmentation_network = self.build_network_architecture(\n",
    "\t\t\t\tself.configuration_manager.network_arch_class_name,\n",
    "\t\t\t\tself.configuration_manager.network_arch_init_kwargs,\n",
    "\t\t\t\tself.configuration_manager.network_arch_init_kwargs_req_import,\n",
    "\t\t\t\tself.num_input_channels,\n",
    "\t\t\t\tself.label_manager.num_segmentation_heads,\n",
    "\t\t\t\tself.enable_deep_supervision,\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# Extract encoder and add classification head\n",
    "\t\t\tself.network = self._build_classification_network(self.segmentation_network)\n",
    "\t\t\tself.network = self.network.to(self.device)\n",
    "\n",
    "\t\t\t# Compile network if enabled\n",
    "\t\t\tif self._do_i_compile():\n",
    "\t\t\t\tself.print_to_log_file('Using torch.compile...')\n",
    "\t\t\t\tself.network = torch.compile(self.network)\n",
    "\n",
    "\t\t\t# Configure optimizers\n",
    "\t\t\tself.optimizer, self.lr_scheduler = self.configure_optimizers()\n",
    "\n",
    "\t\t\t# Wrap in DDP if needed\n",
    "\t\t\tif self.is_ddp:\n",
    "\t\t\t\tself.network = torch.nn.SyncBatchNorm.convert_sync_batchnorm(self.network)\n",
    "\t\t\t\tfrom torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\t\t\t\tself.network = DDP(self.network, device_ids=[self.local_rank])\n",
    "\n",
    "\t\t\t# Build loss function\n",
    "\t\t\tself.loss = self._build_loss()\n",
    "\n",
    "\t\t\t# Set custom dataset class\n",
    "\t\t\tself.dataset_class = nnUNetDatasetBlosc2MultiLabel\n",
    "\n",
    "\t\t\tself.was_initialized = True\n",
    "\t\telse:\n",
    "\t\t\traise RuntimeError('Trainer already initialized')\n",
    "\n",
    "\tdef _build_classification_network(self, segmentation_network):\n",
    "\t\t\"\"\"Build classification network using encoder from segmentation network.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t    segmentation_network: Full nnUNet segmentation network.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t    nn.Module: Classification network with encoder + classification head.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# Create a wrapper that combines encoder and classification head\n",
    "\t\tclass EncoderClassificationNetwork(nn.Module):\n",
    "\t\t\tdef __init__(self, encoder, classification_head):\n",
    "\t\t\t\tsuper().__init__()\n",
    "\t\t\t\tself.encoder = encoder\n",
    "\t\t\t\tself.classification_head = classification_head\n",
    "\t\t\t\t# dummy decoder module\n",
    "\t\t\t\tself.decoder = nn.Module()\n",
    "\n",
    "\t\t\tdef forward(self, x):\n",
    "\t\t\t\t# Get encoder features (before final segmentation layers)\n",
    "\t\t\t\tencoder_features = self.encoder(x)\n",
    "\n",
    "\t\t\t\t# If encoder returns multiple scales (deep supervision), use the highest resolution\n",
    "\t\t\t\tif isinstance(encoder_features, (list, tuple)):\n",
    "\t\t\t\t\tencoder_features = encoder_features[0]\n",
    "\n",
    "\t\t\t\t# Apply classification head\n",
    "\t\t\t\treturn self.classification_head(encoder_features)\n",
    "\n",
    "\t\t# Extract encoder part - this depends on the specific architecture\n",
    "\t\t# For most nnUNet architectures, we can use the encoder directly\n",
    "\t\tif hasattr(segmentation_network, 'encoder'):\n",
    "\t\t\tencoder = segmentation_network.encoder\n",
    "\t\t\t# Get the number of features from the encoder output\n",
    "\t\t\t# This is architecture-dependent, we'll estimate from the decoder input\n",
    "\t\t\tif hasattr(segmentation_network, 'decoder') and hasattr(\n",
    "\t\t\t\tsegmentation_network.decoder, 'conv_blocks_context'\n",
    "\t\t\t):\n",
    "\t\t\t\t# For Generic_UNet architecture\n",
    "\t\t\t\tencoder_features = segmentation_network.decoder.conv_blocks_context[\n",
    "\t\t\t\t\t-1\n",
    "\t\t\t\t].output_channels\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Fallback: assume 512 features (common for nnUNet)\n",
    "\t\t\t\tencoder_features = 32\n",
    "\t\telse:\n",
    "\t\t\t# If no explicit encoder attribute, we'll use the whole network but modify the forward\n",
    "\t\t\t# This is a more general approach that should work with most architectures\n",
    "\t\t\tencoder = segmentation_network\n",
    "\t\t\tencoder_features = 32  # This might need adjustment based on actual architecture\n",
    "\n",
    "\t\t# Create classification head\n",
    "\t\tclassification_head = ClassificationHead(\n",
    "\t\t\tin_features=encoder_features, num_classes=self.num_classes, dropout_rate=0.5\n",
    "\t\t)\n",
    "\n",
    "\t\treturn EncoderClassificationNetwork(encoder, classification_head)\n",
    "\n",
    "\tdef _build_loss(self):\n",
    "\t\t\"\"\"Build binary cross-entropy loss for multi-label classification.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t    nn.Module: Binary cross-entropy loss with logits.\n",
    "\t\t\"\"\"\n",
    "\t\treturn nn.BCEWithLogitsLoss()\n",
    "\n",
    "\tdef get_tr_and_val_datasets(self):\n",
    "\t\t\"\"\"Get training and validation datasets using custom multi-label dataset class.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t    tuple: (training_dataset, validation_dataset)\n",
    "\t\t\"\"\"\n",
    "\t\t# Create dataset split\n",
    "\t\ttr_keys, val_keys = self.do_split()\n",
    "\n",
    "\t\t# Load datasets with CSV path for multi-label annotations\n",
    "\t\tdataset_tr = self.dataset_class(\n",
    "\t\t\tfolder=self.preprocessed_dataset_folder,\n",
    "\t\t\tcsv_path=self.csv_path,\n",
    "\t\t\tidentifiers=tr_keys,\n",
    "\t\t\tfolder_with_segs_from_previous_stage=self.folder_with_segs_from_previous_stage,\n",
    "\t\t)\n",
    "\t\tdataset_val = self.dataset_class(\n",
    "\t\t\tfolder=self.preprocessed_dataset_folder,\n",
    "\t\t\tcsv_path=self.csv_path,\n",
    "\t\t\tidentifiers=val_keys,\n",
    "\t\t\tfolder_with_segs_from_previous_stage=self.folder_with_segs_from_previous_stage,\n",
    "\t\t)\n",
    "\t\treturn dataset_tr, dataset_val\n",
    "\n",
    "\tdef train_step(self, batch: dict) -> dict:\n",
    "\t\t\"\"\"Execute one training step for multi-label classification.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t    batch (dict): Batch containing 'data' and 'target' keys.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t    dict: Dictionary containing loss value.\n",
    "\t\t\"\"\"\n",
    "\t\tdata = batch['data']\n",
    "\t\ttarget = batch['target']  # This will be the multi-label target from CSV\n",
    "\n",
    "\t\tdata = data.to(self.device, non_blocking=True)\n",
    "\t\ttarget = target.to(self.device, non_blocking=True).float()  # Ensure float for BCE loss\n",
    "\n",
    "\t\tself.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "\t\twith (\n",
    "\t\t\tautocast(self.device.type, enabled=True)\n",
    "\t\t\tif self.device.type == 'cuda'\n",
    "\t\t\telse dummy_context()\n",
    "\t\t):\n",
    "\t\t\toutput = self.network(data)  # Shape: (batch_size, num_classes)\n",
    "\t\t\tloss = self.loss(output, target)\n",
    "\n",
    "\t\tif self.grad_scaler is not None:\n",
    "\t\t\tself.grad_scaler.scale(loss).backward()\n",
    "\t\t\tself.grad_scaler.unscale_(self.optimizer)\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "\t\t\tself.grad_scaler.step(self.optimizer)\n",
    "\t\t\tself.grad_scaler.update()\n",
    "\t\telse:\n",
    "\t\t\tloss.backward()\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "\t\t\tself.optimizer.step()\n",
    "\n",
    "\t\treturn {'loss': loss.detach().cpu().numpy()}\n",
    "\n",
    "\tdef validation_step(self, batch: dict) -> dict:\n",
    "\t\t\"\"\"Execute one validation step for multi-label classification.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t    batch (dict): Batch containing 'data' and 'target' keys.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t    dict: Dictionary containing loss and predictions.\n",
    "\t\t\"\"\"\n",
    "\t\tdata = batch['data']\n",
    "\t\ttarget = batch['target']\n",
    "\n",
    "\t\tdata = data.to(self.device, non_blocking=True)\n",
    "\t\ttarget = target.to(self.device, non_blocking=True).float()\n",
    "\n",
    "\t\twith (\n",
    "\t\t\tautocast(self.device.type, enabled=True)\n",
    "\t\t\tif self.device.type == 'cuda'\n",
    "\t\t\telse dummy_context()\n",
    "\t\t):\n",
    "\t\t\toutput = self.network(data)\n",
    "\t\t\tloss = self.loss(output, target)\n",
    "\n",
    "\t\t# Convert predictions to binary (threshold at 0.5)\n",
    "\t\tpredictions = (torch.sigmoid(output) > 0.5).float()\n",
    "\n",
    "\t\t# Calculate per-class accuracy\n",
    "\t\tcorrect_predictions = (predictions == target).float()\n",
    "\t\tper_class_accuracy = correct_predictions.mean(dim=0)  # Average over batch\n",
    "\n",
    "\t\treturn {\n",
    "\t\t\t'loss': loss.detach().cpu().numpy(),\n",
    "\t\t\t'predictions': predictions.detach().cpu().numpy(),\n",
    "\t\t\t'targets': target.detach().cpu().numpy(),\n",
    "\t\t\t'per_class_accuracy': per_class_accuracy.detach().cpu().numpy(),\n",
    "\t\t}\n",
    "\n",
    "\tdef on_validation_epoch_end(self, val_outputs: List[dict]):\n",
    "\t\t\"\"\"Process validation epoch results and log metrics.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t    val_outputs (List[dict]): List of validation step outputs.\n",
    "\t\t\"\"\"\n",
    "\t\tfrom nnunetv2.utilities.collate_outputs import collate_outputs\n",
    "\n",
    "\t\toutputs = collate_outputs(val_outputs)\n",
    "\n",
    "\t\tif self.is_ddp:\n",
    "\t\t\tlosses_val = [None for _ in range(dist.get_world_size())]\n",
    "\t\t\tdist.all_gather_object(losses_val, outputs['loss'])\n",
    "\t\t\tloss_here = np.vstack(losses_val).mean()\n",
    "\n",
    "\t\t\taccuracies_val = [None for _ in range(dist.get_world_size())]\n",
    "\t\t\tdist.all_gather_object(accuracies_val, outputs['per_class_accuracy'])\n",
    "\t\t\tper_class_acc = np.vstack(accuracies_val).mean(axis=0)\n",
    "\t\telse:\n",
    "\t\t\tloss_here = np.mean(outputs['loss'])\n",
    "\t\t\tper_class_acc = np.mean(outputs['per_class_accuracy'], axis=0)\n",
    "\n",
    "\t\tself.logger.log('val_losses', loss_here, self.current_epoch)\n",
    "\n",
    "\t\t# Log per-class accuracies\n",
    "\t\tclass_names = [\n",
    "\t\t\t'epidural',\n",
    "\t\t\t'intraparenchymal',\n",
    "\t\t\t'intraventricular',\n",
    "\t\t\t'subarachnoid',\n",
    "\t\t\t'subdural',\n",
    "\t\t]\n",
    "\t\tfor i, class_name in enumerate(class_names):\n",
    "\t\t\tself.logger.log(f'val_acc_{class_name}', per_class_acc[i], self.current_epoch)\n",
    "\n",
    "\t\t# Log mean accuracy across all classes\n",
    "\t\tmean_accuracy = per_class_acc.mean()\n",
    "\t\tself.logger.log('val_acc_mean', mean_accuracy, self.current_epoch)\n",
    "\n",
    "\t\tself.print_to_log_file(f'Validation loss: {loss_here:.4f}')\n",
    "\t\tself.print_to_log_file(f'Validation mean accuracy: {mean_accuracy:.4f}')\n",
    "\t\tfor i, class_name in enumerate(class_names):\n",
    "\t\t\tself.print_to_log_file(f'Validation {class_name} accuracy: {per_class_acc[i]:.4f}')\n",
    "\n",
    "\tdef do_split(self):\n",
    "\t\t\"\"\"\n",
    "\t\tThe default split is a 5 fold CV on all available training cases. nnU-Net will create a split (it is seeded,\n",
    "\t\tso always the same) and save it as splits_final.json file in the preprocessed data directory.\n",
    "\t\tSometimes you may want to create your own split for various reasons. For this you will need to create your own\n",
    "\t\tsplits_final.json file. If this file is present, nnU-Net is going to use it and whatever splits are defined in\n",
    "\t\tit. You can create as many splits in this file as you want. Note that if you define only 4 splits (fold 0-3)\n",
    "\t\tand then set fold=4 when training (that would be the fifth split), nnU-Net will print a warning and proceed to\n",
    "\t\tuse a random 80:20 data split.\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\tif self.dataset_class is None:\n",
    "\t\t\traise ValueError('Dataset class is not set')\n",
    "\n",
    "\t\tif self.fold == 'all':\n",
    "\t\t\t# if fold==all then we use all images for training and validation\n",
    "\t\t\tcase_identifiers = self.dataset_class.get_identifiers(self.preprocessed_dataset_folder)\n",
    "\t\t\ttr_keys = case_identifiers\n",
    "\t\t\tval_keys = tr_keys\n",
    "\t\telse:\n",
    "\t\t\tsplits_file = join(self.preprocessed_dataset_folder_base, 'splits_final.json')\n",
    "\t\t\tdataset = self.dataset_class(\n",
    "\t\t\t\tself.preprocessed_dataset_folder,\n",
    "\t\t\t\tidentifiers=None,\n",
    "\t\t\t\tfolder_with_segs_from_previous_stage=self.folder_with_segs_from_previous_stage,\n",
    "\t\t\t\tcsv_path=self.csv_path,\n",
    "\t\t\t)\n",
    "\t\t\t# if the split file does not exist we need to create it\n",
    "\t\t\tif not isfile(splits_file):\n",
    "\t\t\t\tself.print_to_log_file('Creating new 5-fold cross-validation split...')\n",
    "\t\t\t\tall_keys_sorted = list(np.sort(list(dataset.identifiers)))\n",
    "\t\t\t\tsplits = generate_crossval_split(all_keys_sorted, seed=12345, n_splits=5)\n",
    "\t\t\t\tsave_json(splits, splits_file)\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.print_to_log_file('Using splits from existing split file:', splits_file)\n",
    "\t\t\t\tsplits = load_json(splits_file)\n",
    "\t\t\t\tself.print_to_log_file(f'The split file contains {len(splits)} splits.')\n",
    "\n",
    "\t\t\tself.print_to_log_file('Desired fold for training: %d' % self.fold)\n",
    "\t\t\tif self.fold < len(splits):\n",
    "\t\t\t\ttr_keys = splits[self.fold]['train']\n",
    "\t\t\t\tval_keys = splits[self.fold]['val']\n",
    "\t\t\t\tself.print_to_log_file(\n",
    "\t\t\t\t\t'This split has %d training and %d validation cases.'\n",
    "\t\t\t\t\t% (len(tr_keys), len(val_keys))\n",
    "\t\t\t\t)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.print_to_log_file(\n",
    "\t\t\t\t\t'INFO: You requested fold %d for training but splits '\n",
    "\t\t\t\t\t'contain only %d folds. I am now creating a '\n",
    "\t\t\t\t\t'random (but seeded) 80:20 split!' % (self.fold, len(splits))\n",
    "\t\t\t\t)\n",
    "\t\t\t\t# if we request a fold that is not in the split file, create a random 80:20 split\n",
    "\t\t\t\trnd = np.random.RandomState(seed=12345 + self.fold)\n",
    "\t\t\t\tkeys = np.sort(list(dataset.identifiers))\n",
    "\t\t\t\tidx_tr = rnd.choice(len(keys), int(len(keys) * 0.8), replace=False)\n",
    "\t\t\t\tidx_val = [i for i in range(len(keys)) if i not in idx_tr]\n",
    "\t\t\t\ttr_keys = [keys[i] for i in idx_tr]\n",
    "\t\t\t\tval_keys = [keys[i] for i in idx_val]\n",
    "\t\t\t\tself.print_to_log_file(\n",
    "\t\t\t\t\t'This random 80:20 split has %d training and %d validation cases.'\n",
    "\t\t\t\t\t% (len(tr_keys), len(val_keys))\n",
    "\t\t\t\t)\n",
    "\t\t\tif any([i in val_keys for i in tr_keys]):\n",
    "\t\t\t\tself.print_to_log_file(\n",
    "\t\t\t\t\t'WARNING: Some validation cases are also in the training set. Please check the '\n",
    "\t\t\t\t\t'splits.json or ignore if this is intentional.'\n",
    "\t\t\t\t)\n",
    "\t\treturn tr_keys, val_keys\n",
    "\n",
    "\tdef get_dataloaders(self):\n",
    "\t\tif self.dataset_class is None:\n",
    "\t\t\traise ValueError('Dataset class is not set')\n",
    "\n",
    "\t\t# we use the patch size to determine whether we need 2D or 3D dataloaders. We also use it to determine whether\n",
    "\t\t# we need to use dummy 2D augmentation (in case of 3D training) and what our initial patch size should be\n",
    "\t\tpatch_size = self.configuration_manager.patch_size\n",
    "\n",
    "\t\t# needed for deep supervision: how much do we need to downscale the segmentation targets for the different\n",
    "\t\t# outputs?\n",
    "\t\tdeep_supervision_scales = self._get_deep_supervision_scales()\n",
    "\n",
    "\t\t(\n",
    "\t\t\trotation_for_DA,\n",
    "\t\t\tdo_dummy_2d_data_aug,\n",
    "\t\t\tinitial_patch_size,\n",
    "\t\t\tmirror_axes,\n",
    "\t\t) = self.configure_rotation_dummyDA_mirroring_and_inital_patch_size()\n",
    "\n",
    "\t\t# training pipeline\n",
    "\t\ttr_transforms = self.get_training_transforms(\n",
    "\t\t\tpatch_size,\n",
    "\t\t\trotation_for_DA,\n",
    "\t\t\tdeep_supervision_scales,\n",
    "\t\t\tmirror_axes,\n",
    "\t\t\tdo_dummy_2d_data_aug,\n",
    "\t\t\tuse_mask_for_norm=self.configuration_manager.use_mask_for_norm,\n",
    "\t\t\tis_cascaded=self.is_cascaded,\n",
    "\t\t\tforeground_labels=self.label_manager.foreground_labels,\n",
    "\t\t\tregions=self.label_manager.foreground_regions\n",
    "\t\t\tif self.label_manager.has_regions\n",
    "\t\t\telse None,\n",
    "\t\t\tignore_label=self.label_manager.ignore_label,\n",
    "\t\t)\n",
    "\n",
    "\t\t# validation pipeline\n",
    "\t\tval_transforms = self.get_validation_transforms(\n",
    "\t\t\tdeep_supervision_scales,\n",
    "\t\t\tis_cascaded=self.is_cascaded,\n",
    "\t\t\tforeground_labels=self.label_manager.foreground_labels,\n",
    "\t\t\tregions=self.label_manager.foreground_regions\n",
    "\t\t\tif self.label_manager.has_regions\n",
    "\t\t\telse None,\n",
    "\t\t\tignore_label=self.label_manager.ignore_label,\n",
    "\t\t)\n",
    "\n",
    "\t\tdataset_tr, dataset_val = self.get_tr_and_val_datasets()\n",
    "\n",
    "\t\tdl_tr = nnUNetDataLoaderMultiLabel(\n",
    "\t\t\tdataset_tr,\n",
    "\t\t\tself.batch_size,\n",
    "\t\t\tinitial_patch_size,\n",
    "\t\t\tself.configuration_manager.patch_size,\n",
    "\t\t\tself.label_manager,\n",
    "\t\t\toversample_foreground_percent=self.oversample_foreground_percent,\n",
    "\t\t\tsampling_probabilities=None,\n",
    "\t\t\tpad_sides=None,\n",
    "\t\t\ttransforms=tr_transforms,\n",
    "\t\t\tprobabilistic_oversampling=self.probabilistic_oversampling,\n",
    "\t\t)\n",
    "\t\tdl_val = nnUNetDataLoaderMultiLabel(\n",
    "\t\t\tdataset_val,\n",
    "\t\t\tself.batch_size,\n",
    "\t\t\tself.configuration_manager.patch_size,\n",
    "\t\t\tself.configuration_manager.patch_size,\n",
    "\t\t\tself.label_manager,\n",
    "\t\t\toversample_foreground_percent=self.oversample_foreground_percent,\n",
    "\t\t\tsampling_probabilities=None,\n",
    "\t\t\tpad_sides=None,\n",
    "\t\t\ttransforms=val_transforms,\n",
    "\t\t\tprobabilistic_oversampling=self.probabilistic_oversampling,\n",
    "\t\t)\n",
    "\n",
    "\t\tallowed_num_processes = get_allowed_n_proc_DA()\n",
    "\t\tif allowed_num_processes == 0:\n",
    "\t\t\tmt_gen_train = SingleThreadedAugmenter(dl_tr, None)\n",
    "\t\t\tmt_gen_val = SingleThreadedAugmenter(dl_val, None)\n",
    "\t\telse:\n",
    "\t\t\tmt_gen_train = NonDetMultiThreadedAugmenter(\n",
    "\t\t\t\tdata_loader=dl_tr,\n",
    "\t\t\t\ttransform=None,\n",
    "\t\t\t\tnum_processes=allowed_num_processes,\n",
    "\t\t\t\tnum_cached=max(6, allowed_num_processes // 2),\n",
    "\t\t\t\tseeds=None,\n",
    "\t\t\t\tpin_memory=self.device.type == 'cuda',\n",
    "\t\t\t\twait_time=0.002,\n",
    "\t\t\t)\n",
    "\t\t\tmt_gen_val = NonDetMultiThreadedAugmenter(\n",
    "\t\t\t\tdata_loader=dl_val,\n",
    "\t\t\t\ttransform=None,\n",
    "\t\t\t\tnum_processes=max(1, allowed_num_processes // 2),\n",
    "\t\t\t\tnum_cached=max(3, allowed_num_processes // 4),\n",
    "\t\t\t\tseeds=None,\n",
    "\t\t\t\tpin_memory=self.device.type == 'cuda',\n",
    "\t\t\t\twait_time=0.002,\n",
    "\t\t\t)\n",
    "\t\t# # let's get this party started\n",
    "\t\t_ = next(mt_gen_train)\n",
    "\t\t_ = next(mt_gen_val)\n",
    "\t\treturn mt_gen_train, mt_gen_val\n",
    "\n",
    "\tdef on_epoch_end(self):\n",
    "\t\tself.logger.log('epoch_end_timestamps', time.time(), self.current_epoch)\n",
    "\n",
    "\t\tself.print_to_log_file(\n",
    "\t\t\t'train_loss', np.round(self.logger.my_fantastic_logging['train_losses'][-1], decimals=4)\n",
    "\t\t)\n",
    "\t\tself.print_to_log_file(\n",
    "\t\t\t'val_loss', np.round(self.logger.my_fantastic_logging['val_losses'][-1], decimals=4)\n",
    "\t\t)\n",
    "\t\tself.print_to_log_file(\n",
    "\t\t\tf'Epoch time: {np.round(self.logger.my_fantastic_logging[\"epoch_end_timestamps\"][-1] - self.logger.my_fantastic_logging[\"epoch_start_timestamps\"][-1], decimals=2)} s'\n",
    "\t\t)\n",
    "\n",
    "\t\t# handling periodic checkpointing\n",
    "\t\tcurrent_epoch = self.current_epoch\n",
    "\t\tif (current_epoch + 1) % self.save_every == 0 and current_epoch != (self.num_epochs - 1):\n",
    "\t\t\tself.save_checkpoint(join(self.output_folder, 'checkpoint_latest.pth'))\n",
    "\n",
    "\t\t# handle 'best' checkpointing. ema_fg_dice is computed by the logger and can be accessed like this\n",
    "\t\tif (\n",
    "\t\t\tself._best_ema is None\n",
    "\t\t\tor self.logger.my_fantastic_logging['val_acc_mean'][-1] > self._best_ema\n",
    "\t\t):\n",
    "\t\t\tself._best_ema = self.logger.my_fantastic_logging['val_acc_mean'][-1]\n",
    "\t\t\tself.print_to_log_file(\n",
    "\t\t\t\tf'Yayy! New best EMA mean accuracy: {np.round(self._best_ema, decimals=4)}'\n",
    "\t\t\t)\n",
    "\t\t\tself.save_checkpoint(join(self.output_folder, 'checkpoint_best.pth'))\n",
    "\n",
    "\t\tif self.local_rank == 0:\n",
    "\t\t\tself.logger.plot_progress_png(self.output_folder)\n",
    "\n",
    "\t\tself.current_epoch += 1\n",
    "\n",
    "\n",
    "print('nnUNetTrainerMultiLabel class created successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5248a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.paths import nnUNet_preprocessed, nnUNet_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff9613b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed /home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "print(nnUNet_preprocessed, nnUNet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c7fd8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "dict_keys(['mean_fg_dice', 'ema_fg_dice', 'dice_per_class_or_region', 'train_losses', 'val_losses', 'lrs', 'epoch_start_timestamps', 'epoch_end_timestamps', 'val_acc_epidural', 'val_acc_intraparenchymal', 'val_acc_intraventricular', 'val_acc_subarachnoid', 'val_acc_subdural', 'val_acc_mean'])\n",
      "2025-08-25 05:35:19.337247: Using torch.compile...\n"
     ]
    }
   ],
   "source": [
    "# folder=\"../Dataset003_MBHClassify/Dataset003_MBHClassify/nnUNetPlans.json\",\n",
    "# csv_path=\"../case-wise_annotation.csv\",\n",
    "\n",
    "# plans = load_json('D:/Learning/UALBERTA/nnUnet/nnUNet_preprocessed/Dataset003_MBHClassify/nnUNetResEncUNetLPlans.json')\n",
    "# dataset_json = load_json('D:/Learning/UALBERTA/nnUnet/nnUNet_preprocessed/Dataset003_MBHClassify/dataset.json')\n",
    "\n",
    "plans = load_json('./nnUNet_preprocessed/Dataset003_MBHClassify/nnUNetResEncUNetLPlans.json')\n",
    "dataset_json = load_json('./nnUNet_preprocessed/Dataset003_MBHClassify/dataset.json')\n",
    "\n",
    "# Initialize the multi-label trainer\n",
    "trainer = nnUNetTrainerMultiLabel(\n",
    "\tplans=plans,\n",
    "\tconfiguration='3d_fullres',  # or whatever configuration you're using\n",
    "\tfold=0,  # cross-validation fold\n",
    "\tdataset_json=dataset_json,\n",
    "\t# csv_path='D:/Learning/UALBERTA/MBH_Train_2025_case-label/case-wise_annotation.csv',\n",
    "\tdevice=torch.device(type='cuda'),\n",
    ")\n",
    "\n",
    "# Initialize the trainer (this sets up the network, loss, optimizer, etc.)\n",
    "trainer.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f4b9742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 05:36:01.742972: do_dummy_2d_data_aug: True\n",
      "2025-08-25 05:36:01.794742: Using splits from existing split file: /home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed/Dataset003_MBHClassify/splits_final.json\n",
      "2025-08-25 05:36:01.802774: The split file contains 5 splits.\n",
      "2025-08-25 05:36:01.805505: Desired fold for training: 0\n",
      "2025-08-25 05:36:01.807780: This split has 1579 training and 395 validation cases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 320, 320], 'median_image_size_in_voxels': [59.5, 512.0, 512.0], 'spacing': [2.7851988792419435, 0.4882810115814209, 0.4882810115814209], 'normalization_schemes': ['CTNormalization', 'NoNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset003_MBHClassify', 'plans_name': 'nnUNetResEncUNetLPlans', 'original_median_spacing_after_transp': [5.0430450439453125, 0.4882810115814209, 0.4882810115814209], 'original_median_shape_after_transp': [32, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncL', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1241.0, 'mean': 47.706321716308594, 'median': 47.0, 'min': -3024.0, 'percentile_00_5': 11.0, 'percentile_99_5': 88.0, 'std': 18.544885635375977}, '1': {'max': 1.0, 'mean': 0.5401495099067688, 'median': 1.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 1.0, 'std': 0.49838340282440186}}} \n",
      "\n",
      "2025-08-25 05:36:18.849845: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-08-25 05:36:18.872418: \n",
      "2025-08-25 05:36:18.874318: Epoch 0\n",
      "2025-08-25 05:36:18.876951: Current learning rate: 0.01\n",
      "2025-08-25 05:37:19.288777: Validation loss: 0.6931\n",
      "2025-08-25 05:37:19.299007: Validation mean accuracy: 1.0000\n",
      "2025-08-25 05:37:19.302461: Validation epidural accuracy: 1.0000\n",
      "2025-08-25 05:37:19.304411: Validation intraparenchymal accuracy: 1.0000\n",
      "2025-08-25 05:37:19.307653: Validation intraventricular accuracy: 1.0000\n",
      "2025-08-25 05:37:19.309546: Validation subarachnoid accuracy: 1.0000\n",
      "2025-08-25 05:37:19.311459: Validation subdural accuracy: 1.0000\n",
      "2025-08-25 05:37:19.314704: train_loss 0.731\n",
      "2025-08-25 05:37:19.316788: val_loss 0.6931\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1381\u001b[39m, in \u001b[36mnnUNetTrainer.run_training\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1378\u001b[39m             val_outputs.append(\u001b[38;5;28mself\u001b[39m.validation_step(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataloader_val)))\n\u001b[32m   1379\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_validation_epoch_end(val_outputs)\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[38;5;28mself\u001b[39m.on_train_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1129\u001b[39m, in \u001b[36mnnUNetTrainer.on_epoch_end\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1126\u001b[39m \u001b[38;5;28mself\u001b[39m.print_to_log_file(\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m, np.round(\u001b[38;5;28mself\u001b[39m.logger.my_fantastic_logging[\u001b[33m'\u001b[39m\u001b[33mtrain_losses\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m], decimals=\u001b[32m4\u001b[39m))\n\u001b[32m   1127\u001b[39m \u001b[38;5;28mself\u001b[39m.print_to_log_file(\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, np.round(\u001b[38;5;28mself\u001b[39m.logger.my_fantastic_logging[\u001b[33m'\u001b[39m\u001b[33mval_losses\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m], decimals=\u001b[32m4\u001b[39m))\n\u001b[32m   1128\u001b[39m \u001b[38;5;28mself\u001b[39m.print_to_log_file(\u001b[33m'\u001b[39m\u001b[33mPseudo dice\u001b[39m\u001b[33m'\u001b[39m, [np.round(i, decimals=\u001b[32m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m                                        \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmy_fantastic_logging\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdice_per_class_or_region\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m])\n\u001b[32m   1130\u001b[39m \u001b[38;5;28mself\u001b[39m.print_to_log_file(\n\u001b[32m   1131\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.round(\u001b[38;5;28mself\u001b[39m.logger.my_fantastic_logging[\u001b[33m'\u001b[39m\u001b[33mepoch_end_timestamps\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.logger.my_fantastic_logging[\u001b[33m'\u001b[39m\u001b[33mepoch_start_timestamps\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m],\u001b[38;5;250m \u001b[39mdecimals=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1133\u001b[39m \u001b[38;5;66;03m# handling periodic checkpointing\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Run the training\n",
    "trainer.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68119a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranashah/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "predictor_3d = nnUNetPredictor(\n",
    "\ttile_step_size=0.5,\n",
    "\tuse_gaussian=True,\n",
    "\tuse_mirroring=True,\n",
    "\tperform_everything_on_device=True,\n",
    "\tdevice=device,\n",
    "\tverbose=False,\n",
    "\tverbose_preprocessing=False,\n",
    "\tallow_tqdm=True,\n",
    ")\n",
    "\n",
    "predictor_3d.initialize_from_trained_model_folder(\n",
    "\t'models/multiclass/nnUNetTrainerDA5__nnUNetResEncUNetLPlans__3d_fullres',\n",
    "\tuse_folds=(0, 1, 2, 3, 4),\n",
    "\tcheckpoint_name='checkpoint_best.pth',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8008f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = predictor_3d.network.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a6de9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualEncoder(\n",
      "  (stem): StackedConvBlocks(\n",
      "    (convs): Sequential(\n",
      "      (0): ConvDropoutNormReLU(\n",
      "        (conv): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "        (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (all_modules): Sequential(\n",
      "          (0): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "          (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(trainer.network.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf6dbb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualEncoder(\n",
      "  (stem): StackedConvBlocks(\n",
      "    (convs): Sequential(\n",
      "      (0): ConvDropoutNormReLU(\n",
      "        (conv): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "        (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (all_modules): Sequential(\n",
      "          (0): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "          (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "            (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "              (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "            (1): ConvDropoutNormReLU(\n",
      "              (conv): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (all_modules): Sequential(\n",
      "                (0): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=0)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): StackedResidualBlocks(\n",
      "      (blocks): Sequential(\n",
      "        (0): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (skip): Sequential(\n",
      "            (0): AvgPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (2): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (3): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (4): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (5): BasicBlockD(\n",
      "          (conv1): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (conv2): ConvDropoutNormReLU(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (all_modules): Sequential(\n",
      "              (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "              (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (nonlin2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(predictor_3d.network.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9fa42b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the encoder weights and gradients from predictor_3d.network.encoder into trainer.network.encoder\n",
    "\n",
    "trainer.network.encoder.load_state_dict(predictor_3d.network.encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bd2a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trainer network checkpoint\n",
    "\n",
    "torch.save(trainer.network.state_dict(), 'trainer_network_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca0937d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 05:06:07.953890: do_dummy_2d_data_aug: True\n",
      "2025-08-25 05:06:07.973145: Using splits from existing split file: /home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed/Dataset003_MBHClassify/splits_final.json\n",
      "2025-08-25 05:06:07.984360: The split file contains 5 splits.\n",
      "2025-08-25 05:06:07.987758: Desired fold for training: 0\n",
      "2025-08-25 05:06:07.992271: This split has 1579 training and 395 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "torch.Size([2, 2, 40, 320, 320])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "dataloader_train, dataloader_val = trainer.get_dataloaders()\n",
    "\n",
    "# get the first batch\n",
    "batch = next(iter(dataloader_train))\n",
    "\n",
    "# get the first image\n",
    "image = batch['data']\n",
    "\n",
    "# get the first label\n",
    "label = batch['target']\n",
    "\n",
    "# print the shape of the image and label\n",
    "print(image.shape)\n",
    "print(label.shape)\n",
    "\n",
    "# print the first image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65dccd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': array(0.9654873, dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24cfd9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-25 05:14:27.412729: do_dummy_2d_data_aug: True\n",
      "2025-08-25 05:14:27.439139: Using splits from existing split file: /home/ranashah/scratch/MBH-SEG-2024-winning-solution/nnUNet_preprocessed/Dataset003_MBHClassify/splits_final.json\n",
      "2025-08-25 05:14:27.450001: The split file contains 5 splits.\n",
      "2025-08-25 05:14:27.451560: Desired fold for training: 0\n",
      "2025-08-25 05:14:27.455410: This split has 1579 training and 395 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EncoderClassificationNetwork' object has no attribute 'decoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:1363\u001b[39m, in \u001b[36mnnUNetTrainer.run_training\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_training\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mon_train_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.current_epoch, \u001b[38;5;28mself\u001b[39m.num_epochs):\n\u001b[32m   1366\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_epoch_start()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:905\u001b[39m, in \u001b[36mnnUNetTrainer.on_train_start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    902\u001b[39m maybe_mkdir_p(\u001b[38;5;28mself\u001b[39m.output_folder)\n\u001b[32m    904\u001b[39m \u001b[38;5;66;03m# make sure deep supervision is on in the network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_deep_supervision_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menable_deep_supervision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[38;5;28mself\u001b[39m.print_plans()\n\u001b[32m    908\u001b[39m empty_cache(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:892\u001b[39m, in \u001b[36mnnUNetTrainer.set_deep_supervision_enabled\u001b[39m\u001b[34m(self, enabled)\u001b[39m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, OptimizedModule):\n\u001b[32m    890\u001b[39m     mod = mod._orig_mod\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m.deep_supervision = enabled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'EncoderClassificationNetwork' object has no attribute 'decoder'"
     ]
    }
   ],
   "source": [
    "trainer.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4210182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 cases in the source folder\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpredictor_3d\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_from_files\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mfolder_with_segs_from_prev_stage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/inference/predict_from_raw_data.py:256\u001b[39m, in \u001b[36mnnUNetPredictor.predict_from_files\u001b[39m\u001b[34m(self, list_of_lists_or_source_folder, output_folder_or_list_of_truncated_output_files, save_probabilities, overwrite, num_processes_preprocessing, num_processes_segmentation_export, folder_with_segs_from_prev_stage, num_parts, part_id)\u001b[39m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m folder_with_segs_from_prev_stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \\\n\u001b[32m    250\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe requested configuration is a cascaded network. It requires the segmentations of the previous \u001b[39m\u001b[33m'\u001b[39m \\\n\u001b[32m    251\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstage (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.configuration_manager.previous_stage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) as input. Please provide the folder where\u001b[39m\u001b[33m'\u001b[39m \\\n\u001b[32m    252\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m they are located via folder_with_segs_from_prev_stage\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# sort out input and output filenames\u001b[39;00m\n\u001b[32m    255\u001b[39m list_of_lists_or_source_folder, output_filename_truncated, seg_from_prev_stage_files = \\\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_manage_input_and_output_lists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_of_lists_or_source_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m                                        \u001b[49m\u001b[43moutput_folder_or_list_of_truncated_output_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m                                        \u001b[49m\u001b[43mfolder_with_segs_from_prev_stage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                                        \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_of_lists_or_source_folder) == \u001b[32m0\u001b[39m:\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/inference/predict_from_raw_data.py:178\u001b[39m, in \u001b[36mnnUNetPredictor._manage_input_and_output_lists\u001b[39m\u001b[34m(self, list_of_lists_or_source_folder, output_folder_or_list_of_truncated_output_files, folder_with_segs_from_prev_stage, overwrite, part_id, num_parts, save_probabilities)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(list_of_lists_or_source_folder)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cases in the source folder\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    177\u001b[39m list_of_lists_or_source_folder = list_of_lists_or_source_folder[part_id::num_parts]\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m caseids = \u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_json\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfile_ending\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\n\u001b[32m    179\u001b[39m \u001b[43m           \u001b[49m\u001b[43mlist_of_lists_or_source_folder\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    181\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mI am processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_parts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (max process ID is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_parts\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, we start counting with 0!)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(caseids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cases that I would like to predict\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/nnunetv2/inference/predict_from_raw_data.py:178\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(list_of_lists_or_source_folder)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cases in the source folder\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    177\u001b[39m list_of_lists_or_source_folder = list_of_lists_or_source_folder[part_id::num_parts]\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m caseids = [os.path.basename(\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)[:-(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset_json[\u001b[33m'\u001b[39m\u001b[33mfile_ending\u001b[39m\u001b[33m'\u001b[39m]) + \u001b[32m5\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m\n\u001b[32m    179\u001b[39m            list_of_lists_or_source_folder]\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    181\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mI am processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_parts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (max process ID is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_parts\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, we start counting with 0!)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(caseids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cases that I would like to predict\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "predictor_3d.predict_from_files(\n",
    "\t'test_data',\n",
    "\t'output_data',\n",
    "\tsave_probabilities=True,\n",
    "\toverwrite=True,\n",
    "\tfolder_with_segs_from_prev_stage=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f7c1e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 2, 1, 3, 3], expected input[2, 1, 40, 320, 320] to have 2 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpredictor_3d\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/dynamic_network_architectures/architectures/unet.py:180\u001b[39m, in \u001b[36mResidualEncoderUNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     skips = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.decoder(skips)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/dynamic_network_architectures/building_blocks/residual_encoders.py:137\u001b[39m, in \u001b[36mResidualEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     ret = []\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stages:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py:137\u001b[39m, in \u001b[36mStackedConvBlocks.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py:71\u001b[39m, in \u001b[36mConvDropoutNormReLU.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mall_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:725\u001b[39m, in \u001b[36mConv3d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:720\u001b[39m, in \u001b[36mConv3d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv3d(\n\u001b[32m    710\u001b[39m         F.pad(\n\u001b[32m    711\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    718\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    719\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [32, 2, 1, 3, 3], expected input[2, 1, 40, 320, 320] to have 2 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "predictor_3d.network(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c919b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranashah/scratch/MBH-SEG-2024-winning-solution/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "predictor_3d = nnUNetPredictor(\n",
    "\ttile_step_size=0.5,\n",
    "\tuse_gaussian=True,\n",
    "\tuse_mirroring=True,\n",
    "\tperform_everything_on_device=True,\n",
    "\tdevice=device,\n",
    "\tverbose=False,\n",
    "\tverbose_preprocessing=False,\n",
    "\tallow_tqdm=True,\n",
    ")\n",
    "\n",
    "predictor_3d.initialize_from_trained_model_folder(\n",
    "\t'models/multiclass/nnUNetTrainerDA5__nnUNetResEncUNetLPlans__3d_fullres',\n",
    "\tuse_folds=(0, 1, 2, 3, 4),\n",
    "\tcheckpoint_name='checkpoint_best.pth',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
